{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:03.436000Z",
     "start_time": "2020-11-09T16:23:03.426159Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:05.591228Z",
     "start_time": "2020-11-09T16:23:05.564613Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('zhivago.txt', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:05.959115Z",
     "start_time": "2020-11-09T16:23:05.951109Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_trash(text):\n",
    "    no_tags_text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    no_space_sequences_text = re.sub(r'[\\s\\\\xa0]+', ' ', no_tags_text).strip()\n",
    "    text_till_last_sentence = f\"{no_space_sequences_text.rsplit('.', 1)[0]}.\"\n",
    "    return text_till_last_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:06.629589Z",
     "start_time": "2020-11-09T16:23:06.410056Z"
    }
   },
   "outputs": [],
   "source": [
    "text = remove_trash(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:07.338683Z",
     "start_time": "2020-11-09T16:23:07.317167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Борис Леонидович Пастернак Доктор Живаго «Доктор Живаго» - итоговое произведение Бориса Пастернака, книга всей его жизни. Этот роман принес его автору мировую известность и Нобелевскую премию, присуждение которой обернулось для поэта оголтелой политической травлей, обвинениями в «измене Родине» и в результате стоило ему жизни. «Доктор Живаго» - роман, сама ткань которого убедительнее свидетельствует о чуде, чем все размышления доктора и обобщения автора. Человек, который так пишет, бесконечно много пережил и передумал, и главные его чувства на свете - восхищенное умиление и слезное сострадание; конечно, есть в его мире место и презрению, и холодному отстранению - но не в них суть. Роман Пастернака - оплакивание прежних заблуждений и их жертв; те, кто не разделяет молитвенного восторга перед миром, достойны прежде всего жалости. Перечитывать «Доктора Живаго» стоит именно тогда, когда кажется, что жить не стоит. Тогда десять строк из этого романа могут сделать то же, что делает любовь в одном из стихотворений доктора: «Жизнь вернулась так же беспричинно, как когда-то странно прервалась» . ru Litres Downlo der Litres Downlo der 17. 4.2 8 litres.ru litres-134194 1. Борис Пастернак Доктор Живаго И ДЫШАТ ПОЧВА И СУДЬБА Спустя два года после завершения романа «Доктор Живаго» Борис Пастернак писал: «Я думаю, несмотря на привычность всего того, что продолжает стоять перед нашими глазами и что мы продолжаем слышать и читать, ничего этого больше нет, это уже прошло и состоялось, огромны'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:08.875973Z",
     "start_time": "2020-11-09T16:23:08.865712Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from rusenttokenize import ru_sent_tokenize\n",
    "from razdel import tokenize as razdel_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:22.892168Z",
     "start_time": "2020-11-09T16:23:09.447885Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = ru_sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:23.000350Z",
     "start_time": "2020-11-09T16:23:22.898048Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Мужику дай волю, так ведь у нас друг дружку передавят, истинный Господь.',\n",
       " 'Ай заснули?',\n",
       " 'Это была вторая поездка дяди и племянника в Дуплянку.',\n",
       " 'Юра думал, что он запомнил дорогу, и всякий раз, как поля разбегались вширь и их тоненькой каемкой охватывали спереди и сзади леса, Юре казалось, что он узнает то место, с которого дорога должна повернуть вправо, а с поворота показаться и через минуту скрыться десятиверстная кологривовская панорама с блещущей вдали рекой и пробегающей за ней железной дорогой.',\n",
       " 'Но он все обманывался.',\n",
       " 'Поля сменялись полями.',\n",
       " 'Их вновь и вновь охватывали леса.',\n",
       " 'Смена этих просторов настраивала на широкий лад.',\n",
       " 'Хотелось мечтать и думать о будущем.',\n",
       " 'Ни одна из книг, прославивших впоследствии Николая Николаевича, не была еще написана.']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:23.047251Z",
     "start_time": "2020-11-09T16:23:23.010346Z"
    }
   },
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:23.078311Z",
     "start_time": "2020-11-09T16:23:23.053729Z"
    }
   },
   "outputs": [],
   "source": [
    "punctuation = f'{punctuation}«»–...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.360985Z",
     "start_time": "2020-11-09T16:23:23.082342Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = [token.text.strip(punctuation) for token in razdel_tokenize(text) \n",
    "          if token.text not in punctuation]\n",
    "tokens = [token for token in tokens if token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.376384Z",
     "start_time": "2020-11-09T16:23:26.363840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['борис',\n",
       " 'леонидович',\n",
       " 'пастернак',\n",
       " 'доктор',\n",
       " 'живаго',\n",
       " 'доктор',\n",
       " 'живаго',\n",
       " 'итоговое',\n",
       " 'произведение',\n",
       " 'бориса']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.406863Z",
     "start_time": "2020-11-09T16:23:26.383975Z"
    }
   },
   "outputs": [],
   "source": [
    "# есть ли в тексте повторяющиеся корректные предложения? если да то какие?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.422950Z",
     "start_time": "2020-11-09T16:23:26.414407Z"
    }
   },
   "outputs": [],
   "source": [
    "def sorted_by_freq(lst):\n",
    "    counted_lst = dict(Counter(lst)).items()\n",
    "    sorted_by_freq_counted_lst = sorted(counted_lst, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_by_freq_counted_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.485113Z",
     "start_time": "2020-11-09T16:23:26.426952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('– Да.', 10),\n",
       " ('Да.', 10),\n",
       " ('Не правда ли?', 9),\n",
       " ('А?', 7),\n",
       " ('– Нет.', 7),\n",
       " ('– Хорошо.', 6),\n",
       " ('– Знаю.', 4),\n",
       " ('– Разумеется.', 4),\n",
       " ('Сеялки.', 4),\n",
       " ('Молотилки».', 4),\n",
       " ('Ха-ха-ха!', 3),\n",
       " ('– А как же.', 3),\n",
       " ('Конечно.', 3),\n",
       " ('Где он?', 3),\n",
       " ('Погоди.', 3),\n",
       " ('Маркел!', 3),\n",
       " ('Но дело не в этом.', 3),\n",
       " ('Слушай.', 3),\n",
       " ('Пойдем.', 3),\n",
       " ('Дядя Воронюк!', 3),\n",
       " ('– Еще бы.', 3),\n",
       " ('– Я знаю.', 3),\n",
       " ('Ну да!', 3),\n",
       " ('Свеча горела на столе, Свеча горела.', 3),\n",
       " ('Единственно живое и яркое в вас – это то, что вы жили в одно время со мной и меня знали».',\n",
       "  2),\n",
       " ('Весной в несколько дней лес преображается, подымается до облаков, в его покрытых листьями дебрях можно затеряться, спрятаться.',\n",
       "  2),\n",
       " ('Это превращение достигается движением, по стремительности превосходящим движения животных, потому что животное не растет так быстро, как растение, и которого никогда нельзя подсмотреть.',\n",
       "  2),\n",
       " ('Лес не передвигается, мы не можем его накрыть, подстеречь за переменою места.',\n",
       "  2),\n",
       " ('Мы всегда застаем его в неподвижности.', 2),\n",
       " ('И в такой же неподвижности застигаем мы вечно растущую, вечно меняющуюся, неуследимую в своих превращениях жизнь общества, историю.',\n",
       "  2),\n",
       " ('Толстой не довел своей мысли до конца, когда отрицал роль зачинателей за Наполеоном, правителями, полководцами.',\n",
       "  2),\n",
       " ('Он думал именно то же самое, но не договорил этого со всею ясностью.', 2),\n",
       " ('И через много-много лет Твой голос вновь меня встревожил.', 2),\n",
       " ('Мне к людям хочется, в толпу, В их утреннее оживленье.', 2),\n",
       " ('Я вышел на подмостки.', 2),\n",
       " ('На меня наставлен сумрак ночи Тысячью биноклей на оси.', 2),\n",
       " ('Если только можно, Авва Отче, Чашу эту мимо пронеси.', 2),\n",
       " ('Да, кстати.', 2),\n",
       " ('Вот они.', 2),\n",
       " ('Куда там!', 2),\n",
       " ('– Тсс.', 2),\n",
       " ('Наоборот.', 2),\n",
       " ('– Слушаюсь, барыня.', 2),\n",
       " ('«Женщина или ваза».', 2),\n",
       " ('Вашим.', 2),\n",
       " ('Родя!', 2),\n",
       " ('Я тороплюсь.', 2),\n",
       " ('– Что с тобой?', 2),\n",
       " ('– Что-то знакомое.', 2),\n",
       " ('Кока!', 2),\n",
       " ('Выносят.', 2),\n",
       " ('– Ну конечно.', 2),\n",
       " ('– Спасибо.', 2),\n",
       " ('Парило.', 2),\n",
       " ('Нет.', 2),\n",
       " ('Поразительно!', 2),\n",
       " ('Измен!', 2),\n",
       " ('Так.', 2),\n",
       " ('Ну хорошо.', 2),\n",
       " ('Слушайте.', 2),\n",
       " ('Видите?', 2),\n",
       " ('Вранье, хиромантия.', 2),\n",
       " ('Не слышу.', 2),\n",
       " ('Все в порядке.', 2),\n",
       " ('Прости.', 2),\n",
       " ('Да, представь себе.', 2),\n",
       " ('Ну как же!', 2),\n",
       " ('– Тоня!', 2),\n",
       " ('Быть не может!', 2),\n",
       " ('Какими судьбами?', 2),\n",
       " ('– Правильно.', 2),\n",
       " ('Ты подумай!', 2),\n",
       " ('Это азбука.', 2),\n",
       " ('Ну.', 2),\n",
       " ('– Ну как же!', 2),\n",
       " ('Поздно.', 2),\n",
       " ('Ты не спишь?', 2),\n",
       " ('Послушайте.', 2),\n",
       " ('Некогда.', 2),\n",
       " ('Под конвоем.', 2),\n",
       " ('– Ну да, ну да.', 2),\n",
       " ('Ей-богу, правда.', 2),\n",
       " ('– Здравствуйте.', 2),\n",
       " ('– Ладно.', 2),\n",
       " ('Запамятовал.', 2),\n",
       " ('Живаго...', 2),\n",
       " ('Странно.', 2),\n",
       " ('Гурьян!', 2),\n",
       " ('– Откуда?', 2),\n",
       " ('Будто из Демидовых мы.', 2),\n",
       " ('Что вы сказали?', 2),\n",
       " ('Однако продолжаю.', 2),\n",
       " ('Спасибо.', 2),\n",
       " ('Донат!', 2),\n",
       " ('Не знаю.', 2),\n",
       " ('– Нет, спасибо.', 2),\n",
       " ('Все может быть.', 2),\n",
       " ('Нам посчастливилось.', 2),\n",
       " ('Неужели правда?', 2),\n",
       " ('Надо торопиться.', 2),\n",
       " ('Ну так.', 2),\n",
       " ('– Не надо.', 2),\n",
       " ('Резолюцию!', 2),\n",
       " ('Домовой!', 2),\n",
       " ('Господи!', 2),\n",
       " ('– Нет, зачем.', 2),\n",
       " ('– Запамятовал.', 2),\n",
       " ('Третью беду сказывай.', 2),\n",
       " ('Толпа росла.', 2),\n",
       " ('Я знаю.', 2),\n",
       " ('Но мало того.', 2),\n",
       " ('– Погоди.', 2),\n",
       " ('Что ты делаешь?', 2),\n",
       " ('Как ты думаешь?', 2),\n",
       " ('Хорошо.', 2),\n",
       " ('Завтра утром...', 2),\n",
       " ('Лара!', 2),\n",
       " ('Уехали.', 2),\n",
       " ('Он открыл глаза.', 2),\n",
       " ('– Виноват.', 2),\n",
       " ('Больше я ее не видел.', 2),\n",
       " ('Как я выжил?', 2),\n",
       " ('Сомкнутые веки.', 2),\n",
       " ('Выси.', 2),\n",
       " ('Облака.', 2),\n",
       " ('Воды.', 2),\n",
       " ('Броды.', 2),\n",
       " ('Реки.', 2),\n",
       " ('Годы и века.', 2),\n",
       " ('Светало.', 2)]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent for sent in sorted_by_freq(sentences) if sent[1] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.797913Z",
     "start_time": "2020-11-09T16:23:26.783325Z"
    }
   },
   "outputs": [],
   "source": [
    "# какой самый частотный токен в тексте длиннее 6 символов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:27.976995Z",
     "start_time": "2020-11-09T16:23:27.804188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('андреевич', 289)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in sorted_by_freq(tokens) if len(word[0]) > 6][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:47:54.090998Z",
     "start_time": "2020-11-09T04:47:54.079997Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:47:55.807572Z",
     "start_time": "2020-11-09T04:47:55.788535Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:48:27.708281Z",
     "start_time": "2020-11-09T04:48:00.309189Z"
    }
   },
   "outputs": [],
   "source": [
    "stems = [(token, stemmer.stem(token)) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:48:27.723819Z",
     "start_time": "2020-11-09T04:48:27.712817Z"
    }
   },
   "outputs": [],
   "source": [
    "# два разных слова ошибочно свелись к одинаковой основе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:02:59.374688Z",
     "start_time": "2020-11-09T05:27:33.250327Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "same_stems_for_diff_tokens = [(stem, another_stem) for stem in stems for another_stem in list(set(stems))\n",
    "                              if stem[0] != another_stem[0] and stem[1] == another_stem[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T14:38:45.347159Z",
     "start_time": "2020-11-09T14:38:44.820195Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('не', 'не'), ('нее', 'не')), 2933),\n",
       " ((('не', 'не'), ('нею', 'не')), 2933),\n",
       " ((('не', 'не'), ('ней', 'не')), 2933),\n",
       " ((('он', 'он'), ('оно', 'он')), 1577),\n",
       " ((('он', 'он'), ('они', 'он')), 1577),\n",
       " ((('он', 'он'), ('она', 'он')), 1577),\n",
       " ((('он', 'он'), ('оной', 'он')), 1577),\n",
       " ((('как', 'как'), ('каки', 'как')), 1288),\n",
       " ((('как', 'как'), ('каков', 'как')), 1288),\n",
       " ((('как', 'как'), ('какому', 'как')), 1288),\n",
       " ((('как', 'как'), ('каком', 'как')), 1288),\n",
       " ((('как', 'как'), ('каким', 'как')), 1288),\n",
       " ((('как', 'как'), ('какою', 'как')), 1288),\n",
       " ((('как', 'как'), ('какого', 'как')), 1288),\n",
       " ((('как', 'как'), ('какая', 'как')), 1288),\n",
       " ((('как', 'как'), ('какую', 'как')), 1288),\n",
       " ((('как', 'как'), ('какой', 'как')), 1288),\n",
       " ((('как', 'как'), ('кака', 'как')), 1288),\n",
       " ((('как', 'как'), ('каких', 'как')), 1288),\n",
       " ((('как', 'как'), ('какими', 'как')), 1288),\n",
       " ((('как', 'как'), ('какие', 'как')), 1288),\n",
       " ((('как', 'как'), ('какое', 'как')), 1288),\n",
       " ((('это', 'эт'), ('этих', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этим', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этою', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этому', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этой', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('эту', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этими', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('эта', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этом', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этого', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('эти', 'эт')), 1001),\n",
       " ((('а', 'а'), ('ай', 'а')), 990),\n",
       " ((('по', 'по'), ('поили', 'по')), 964),\n",
       " ((('по', 'по'), ('поила', 'по')), 964),\n",
       " ((('из', 'из'), ('изо', 'из')), 796),\n",
       " ((('все', 'все'), ('всею', 'все')), 761),\n",
       " ((('все', 'все'), ('всей', 'все')), 761),\n",
       " ((('все', 'все'), ('всё', 'все')), 761)]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pair for pair in sorted_by_freq(same_stems_for_diff_tokens)][:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из частотных пар, подходящих под условие, ошибка в стемминге есть в следующих:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_((('не', 'не'), ('нее', 'не')), 2933),   \n",
    " ((('не', 'не'), ('нею', 'не')), 2933),   \n",
    " ((('не', 'не'), ('ней', 'не')), 2933),   \n",
    " ((('а', 'а'), ('ай', 'а')), 990),  \n",
    " ((('из', 'из'), ('изо', 'из')), 796)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первых трех из них у второй пары внутри каждой пары основа должна быть нулевой, а в четвертой и пятой парах у вторых пар основа должна быть одинакова с токеном."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:44.207072Z",
     "start_time": "2020-11-09T16:23:44.195424Z"
    }
   },
   "outputs": [],
   "source": [
    "# слово не изменилось после стемминга (слово должно быть русским и длиннее 4 символов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:44.455387Z",
     "start_time": "2020-11-09T16:23:44.364029Z"
    }
   },
   "outputs": [],
   "source": [
    "unchanged_tokens = [stem for stem in stems if stem[0] == stem[1] and \n",
    "                    len(stem[0]) > 4 and re.search(r'[а-яё]', stem[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:44.548429Z",
     "start_time": "2020-11-09T16:23:44.520198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('андреевич', 'андреевич'), 289),\n",
       " (('доктор', 'доктор'), 226),\n",
       " (('перед', 'перед'), 172),\n",
       " (('может', 'может'), 162),\n",
       " (('через', 'через'), 144),\n",
       " (('будет', 'будет'), 141),\n",
       " (('сейчас', 'сейчас'), 127),\n",
       " (('человек', 'человек'), 112),\n",
       " (('вдруг', 'вдруг'), 109),\n",
       " (('поезд', 'поезд'), 65),\n",
       " (('видел', 'видел'), 53),\n",
       " (('назад', 'назад'), 49),\n",
       " (('гордон', 'гордон'), 47),\n",
       " (('город', 'город'), 45),\n",
       " (('хотел', 'хотел'), 45)]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in sorted_by_freq(unchanged_tokens)][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из частотных пар, подходящих под условие, ошибка в стемминге есть у слов _может, будет, человек, видел, хотел_. Правильными основами были бы соответственно _мо, б,_ нулевая, _ви, хо_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T05:26:24.318110Z",
     "start_time": "2020-11-09T05:19:26.547Z"
    }
   },
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:47.003793Z",
     "start_time": "2020-11-09T16:23:46.991726Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:47.224167Z",
     "start_time": "2020-11-09T16:23:47.211397Z"
    }
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:47.781931Z",
     "start_time": "2020-11-09T16:23:47.761097Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "print(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на 100 самых частотных слов русского языка, собранные на основе данных НКРЯ, и проверим, какие из них отсутствуют в стоп-словах из библиотеки NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:48.976518Z",
     "start_time": "2020-11-09T16:23:48.952003Z"
    }
   },
   "outputs": [],
   "source": [
    "ruscorpora_freqs = ['и', 'в', 'не', 'на', 'я', 'быть', 'он', 'с', 'что', 'а', 'по', 'это', 'она', 'этот', 'к', 'но', 'они', 'мы', 'как', 'из', 'у', 'который', 'то', 'за', 'свой', 'что', 'весь', 'год', 'от', 'так', 'о', 'для', 'ты', 'же', 'все', 'тот', 'мочь', 'вы', 'человек', 'такой', 'его', 'сказать', 'только', 'или', 'ещё', 'бы', 'себя', 'один', 'как', 'уже', 'до', 'время', 'если', 'сам', 'когда', 'другой', 'вот', 'говорить', 'наш', 'мой', 'знать', 'стать', 'при', 'чтобы', 'дело', 'жизнь', 'кто', 'первый', 'очень', 'два', 'день', 'её', 'новый', 'рука', 'даже', 'во', 'со', 'раз', 'где', 'там', 'под', 'можно', 'ну', 'какой', 'после', 'их', 'работа', 'без', 'самый', 'потом', 'надо', 'хотеть', 'ли', 'слово', 'идти', 'большой', 'должен', 'место', 'иметь', 'ничто']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:49.567271Z",
     "start_time": "2020-11-09T16:23:49.555068Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['это', 'который', 'свой', 'весь', 'год', 'мочь', 'человек', 'сказать', 'время', 'говорить', 'наш', 'знать', 'стать', 'дело', 'жизнь', 'первый', 'очень', 'день', 'новый', 'рука', 'работа', 'самый', 'хотеть', 'слово', 'идти', 'большой', 'должен', 'место', 'иметь', 'ничто']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in ruscorpora_freqs if word.replace('ё', 'е') not in stops])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я бы добавила следующие слова, потому что они относятся к служебным частям речи, обладают высокой частотностью и потому невысокой информативностью и формы некоторых из них есть в списке NLTK, но почему-то нет их самых:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. _это_  \n",
    "2. _который_  \n",
    "3. _свой_  \n",
    "4. _весь_  \n",
    "5. _наш_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом список из NLTK нормальный, но странно было обнаружить, что как минимум пять перечисленных выше слов в нем отсутствуют и что некоторые слова есть не во всех формах, причем иногда слова нет в начальной, но есть в косвенных. Смущает, что совсем нет числительных и почти нет вводных слов. Лично я предпочитаю использовать список стоп-слов из библиотеки stop_words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T14:08:49.123775Z",
     "start_time": "2020-11-09T14:08:49.118775Z"
    }
   },
   "source": [
    "### Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:52.793265Z",
     "start_time": "2020-11-09T16:23:52.773090Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:54.000588Z",
     "start_time": "2020-11-09T16:23:53.991153Z"
    }
   },
   "outputs": [],
   "source": [
    "# лемматизируйте токены с помощью pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:54.606328Z",
     "start_time": "2020-11-09T16:23:54.493703Z"
    }
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:55.085031Z",
     "start_time": "2020-11-09T16:23:55.067607Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pymorphy2_lemmatized_text(tokens):\n",
    "    lemmatized_text = [(token, morph.parse(token)[0].normal_form) for token in tokens]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:24:01.993282Z",
     "start_time": "2020-11-09T16:23:55.898307Z"
    }
   },
   "outputs": [],
   "source": [
    "pymorphy2_lemmatized_text = get_pymorphy2_lemmatized_text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:24:02.024065Z",
     "start_time": "2020-11-09T16:24:01.999131Z"
    }
   },
   "outputs": [],
   "source": [
    "# лемматизируйте текст с помощью mystem3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:24:02.055165Z",
     "start_time": "2020-11-09T16:24:02.030093Z"
    }
   },
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:29:15.779663Z",
     "start_time": "2020-11-09T16:29:15.759542Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mystem_lemmatized_text(text):\n",
    "    lemmatized_text = [(lemma['text'], lemma['analysis'][0]['lex']) for lemma in mystem.analyze(text) \n",
    "                       if re.search(r'[а-яёa-z]', lemma['text']) and lemma['analysis']]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:29:30.839315Z",
     "start_time": "2020-11-09T16:29:16.389172Z"
    }
   },
   "outputs": [],
   "source": [
    "mystem_lemmatized_text = get_mystem_lemmatized_text(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:29:30.855253Z",
     "start_time": "2020-11-09T16:29:30.845171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Что в данном случае лучше для лемматизации mystem или pymorphy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на случаи, когда одни и те же токены библиотеки лемматизировали по-разному:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:06:30.942981Z",
     "start_time": "2020-11-09T16:29:30.864024Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_tokens = []\n",
    "pymorphy2_lemmas = []\n",
    "mystem_lemmas = []\n",
    "for pymorphy2_lemma in list(set(pymorphy2_lemmatized_text)):\n",
    "    for mystem_lemma in list(set(mystem_lemmatized_text)):\n",
    "        if pymorphy2_lemma[0] == mystem_lemma[0] and pymorphy2_lemma[1] != mystem_lemma[1]:\n",
    "            unique_tokens.append(pymorphy2_lemma[0])\n",
    "            pymorphy2_lemmas.append(pymorphy2_lemma[1])\n",
    "            mystem_lemmas.append(mystem_lemma[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:06:30.990983Z",
     "start_time": "2020-11-09T17:06:30.945982Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmas_comparison = pd.DataFrame({'Токен': unique_tokens,\n",
    "                                  'Лемма pymorphy2': pymorphy2_lemmas,\n",
    "                                  'Лемма mystem': mystem_lemmas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T18:06:12.235361Z",
     "start_time": "2020-11-09T18:06:12.213370Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Токен</th>\n",
       "      <th>Лемма pymorphy2</th>\n",
       "      <th>Лемма mystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>живее</td>\n",
       "      <td>живой</td>\n",
       "      <td>живо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>поворачиваясь</td>\n",
       "      <td>поворачиваться</td>\n",
       "      <td>повертываться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>запрокинувши</td>\n",
       "      <td>запрокинуть</td>\n",
       "      <td>запрокидывать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>повыгоднее</td>\n",
       "      <td>выгодный</td>\n",
       "      <td>выгодно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>федоровна</td>\n",
       "      <td>фёдор</td>\n",
       "      <td>федоровна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>прочее</td>\n",
       "      <td>прочее</td>\n",
       "      <td>прочий</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8009</th>\n",
       "      <td>побежден</td>\n",
       "      <td>победить</td>\n",
       "      <td>побеждать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>николаевну</td>\n",
       "      <td>николай</td>\n",
       "      <td>николаевна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>позвольте</td>\n",
       "      <td>позволить</td>\n",
       "      <td>позволять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8012</th>\n",
       "      <td>пораженный</td>\n",
       "      <td>поразить</td>\n",
       "      <td>поражать</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Токен Лемма pymorphy2   Лемма mystem\n",
       "0             живее           живой           живо\n",
       "1     поворачиваясь  поворачиваться  повертываться\n",
       "2      запрокинувши     запрокинуть  запрокидывать\n",
       "3        повыгоднее        выгодный        выгодно\n",
       "4         федоровна           фёдор      федоровна\n",
       "...             ...             ...            ...\n",
       "8008         прочее          прочее         прочий\n",
       "8009       побежден        победить      побеждать\n",
       "8010     николаевну         николай     николаевна\n",
       "8011      позвольте       позволить      позволять\n",
       "8012     пораженный        поразить       поражать\n",
       "\n",
       "[8013 rows x 3 columns]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:25:29.132122Z",
     "start_time": "2020-11-09T17:25:29.114082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.244247231602921"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmas_comparison) / len(tokens) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество токенов, которые были лемматизированы по-разному, составляет ~5.2% от общего числа, что, наверное, можно оценить как немного."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдения:  \n",
    "\n",
    "1. pymorphy2 хуже справляется с отчествами, он лемматизирует их как имя, от которого они образованы.  \n",
    "2. Часты разногласия по поводу вида глаголов, в том числе от которых образованы причастия: pymorphy2 предпочитает совершенный вид, mystem — несовершенный; кажется, что pymorphy2 чаще оказывается прав в этом пункте.  \n",
    "3. Проблема со сравнительной степенью наречий и прилагательных: без контекста не определить, образованы они от наречий или от прилагательных, а контекст посмотреть не представляется возможным; pymorphy2 чаще делает выбор в пользу прилагательных, mystem — наречий.\n",
    "4. pymorphy2 пишет \"ё\", mystem вместо \"ё\" пишет \"е\"; я думаю, что с \"ё\" информативнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я не могу уверенно сказать, какая библиотека в данном случае лучше, но после оценки лемматизации случайных токенов из датафрейма выше кажется, что лучше pymorphy2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:03.436000Z",
     "start_time": "2020-11-09T16:23:03.426159Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:05.591228Z",
     "start_time": "2020-11-09T16:23:05.564613Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('zhivago.txt', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:05.959115Z",
     "start_time": "2020-11-09T16:23:05.951109Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_trash(text):\n",
    "    no_tags_text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    no_space_sequences_text = re.sub(r'[\\s\\\\xa0]+', ' ', no_tags_text).strip()\n",
    "    text_till_last_sentence = f\"{no_space_sequences_text.rsplit('.', 1)[0]}.\"\n",
    "    return text_till_last_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:06.629589Z",
     "start_time": "2020-11-09T16:23:06.410056Z"
    }
   },
   "outputs": [],
   "source": [
    "text = remove_trash(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:07.338683Z",
     "start_time": "2020-11-09T16:23:07.317167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Борис Леонидович Пастернак Доктор Живаго «Доктор Живаго» - итоговое произведение Бориса Пастернака, книга всей его жизни. Этот роман принес его автору мировую известность и Нобелевскую премию, присуждение которой обернулось для поэта оголтелой политической травлей, обвинениями в «измене Родине» и в результате стоило ему жизни. «Доктор Живаго» - роман, сама ткань которого убедительнее свидетельствует о чуде, чем все размышления доктора и обобщения автора. Человек, который так пишет, бесконечно много пережил и передумал, и главные его чувства на свете - восхищенное умиление и слезное сострадание; конечно, есть в его мире место и презрению, и холодному отстранению - но не в них суть. Роман Пастернака - оплакивание прежних заблуждений и их жертв; те, кто не разделяет молитвенного восторга перед миром, достойны прежде всего жалости. Перечитывать «Доктора Живаго» стоит именно тогда, когда кажется, что жить не стоит. Тогда десять строк из этого романа могут сделать то же, что делает любовь в одном из стихотворений доктора: «Жизнь вернулась так же беспричинно, как когда-то странно прервалась» . ru Litres Downlo der Litres Downlo der 17. 4.2 8 litres.ru litres-134194 1. Борис Пастернак Доктор Живаго И ДЫШАТ ПОЧВА И СУДЬБА Спустя два года после завершения романа «Доктор Живаго» Борис Пастернак писал: «Я думаю, несмотря на привычность всего того, что продолжает стоять перед нашими глазами и что мы продолжаем слышать и читать, ничего этого больше нет, это уже прошло и состоялось, огромны'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:08.875973Z",
     "start_time": "2020-11-09T16:23:08.865712Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from rusenttokenize import ru_sent_tokenize\n",
    "from razdel import tokenize as razdel_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:22.892168Z",
     "start_time": "2020-11-09T16:23:09.447885Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = ru_sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:23.000350Z",
     "start_time": "2020-11-09T16:23:22.898048Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Мужику дай волю, так ведь у нас друг дружку передавят, истинный Господь.',\n",
       " 'Ай заснули?',\n",
       " 'Это была вторая поездка дяди и племянника в Дуплянку.',\n",
       " 'Юра думал, что он запомнил дорогу, и всякий раз, как поля разбегались вширь и их тоненькой каемкой охватывали спереди и сзади леса, Юре казалось, что он узнает то место, с которого дорога должна повернуть вправо, а с поворота показаться и через минуту скрыться десятиверстная кологривовская панорама с блещущей вдали рекой и пробегающей за ней железной дорогой.',\n",
       " 'Но он все обманывался.',\n",
       " 'Поля сменялись полями.',\n",
       " 'Их вновь и вновь охватывали леса.',\n",
       " 'Смена этих просторов настраивала на широкий лад.',\n",
       " 'Хотелось мечтать и думать о будущем.',\n",
       " 'Ни одна из книг, прославивших впоследствии Николая Николаевича, не была еще написана.']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:23.047251Z",
     "start_time": "2020-11-09T16:23:23.010346Z"
    }
   },
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:23.078311Z",
     "start_time": "2020-11-09T16:23:23.053729Z"
    }
   },
   "outputs": [],
   "source": [
    "punctuation = f'{punctuation}«»–...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.360985Z",
     "start_time": "2020-11-09T16:23:23.082342Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = [token.text.strip(punctuation) for token in razdel_tokenize(text) \n",
    "          if token.text not in punctuation]\n",
    "tokens = [token for token in tokens if token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.376384Z",
     "start_time": "2020-11-09T16:23:26.363840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['борис',\n",
       " 'леонидович',\n",
       " 'пастернак',\n",
       " 'доктор',\n",
       " 'живаго',\n",
       " 'доктор',\n",
       " 'живаго',\n",
       " 'итоговое',\n",
       " 'произведение',\n",
       " 'бориса']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.406863Z",
     "start_time": "2020-11-09T16:23:26.383975Z"
    }
   },
   "outputs": [],
   "source": [
    "# есть ли в тексте повторяющиеся корректные предложения? если да то какие?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.422950Z",
     "start_time": "2020-11-09T16:23:26.414407Z"
    }
   },
   "outputs": [],
   "source": [
    "def sorted_by_freq(lst):\n",
    "    counted_lst = dict(Counter(lst)).items()\n",
    "    sorted_by_freq_counted_lst = sorted(counted_lst, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_by_freq_counted_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.485113Z",
     "start_time": "2020-11-09T16:23:26.426952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('– Да.', 10),\n",
       " ('Да.', 10),\n",
       " ('Не правда ли?', 9),\n",
       " ('А?', 7),\n",
       " ('– Нет.', 7),\n",
       " ('– Хорошо.', 6),\n",
       " ('– Знаю.', 4),\n",
       " ('– Разумеется.', 4),\n",
       " ('Сеялки.', 4),\n",
       " ('Молотилки».', 4),\n",
       " ('Ха-ха-ха!', 3),\n",
       " ('– А как же.', 3),\n",
       " ('Конечно.', 3),\n",
       " ('Где он?', 3),\n",
       " ('Погоди.', 3),\n",
       " ('Маркел!', 3),\n",
       " ('Но дело не в этом.', 3),\n",
       " ('Слушай.', 3),\n",
       " ('Пойдем.', 3),\n",
       " ('Дядя Воронюк!', 3),\n",
       " ('– Еще бы.', 3),\n",
       " ('– Я знаю.', 3),\n",
       " ('Ну да!', 3),\n",
       " ('Свеча горела на столе, Свеча горела.', 3),\n",
       " ('Единственно живое и яркое в вас – это то, что вы жили в одно время со мной и меня знали».',\n",
       "  2),\n",
       " ('Весной в несколько дней лес преображается, подымается до облаков, в его покрытых листьями дебрях можно затеряться, спрятаться.',\n",
       "  2),\n",
       " ('Это превращение достигается движением, по стремительности превосходящим движения животных, потому что животное не растет так быстро, как растение, и которого никогда нельзя подсмотреть.',\n",
       "  2),\n",
       " ('Лес не передвигается, мы не можем его накрыть, подстеречь за переменою места.',\n",
       "  2),\n",
       " ('Мы всегда застаем его в неподвижности.', 2),\n",
       " ('И в такой же неподвижности застигаем мы вечно растущую, вечно меняющуюся, неуследимую в своих превращениях жизнь общества, историю.',\n",
       "  2),\n",
       " ('Толстой не довел своей мысли до конца, когда отрицал роль зачинателей за Наполеоном, правителями, полководцами.',\n",
       "  2),\n",
       " ('Он думал именно то же самое, но не договорил этого со всею ясностью.', 2),\n",
       " ('И через много-много лет Твой голос вновь меня встревожил.', 2),\n",
       " ('Мне к людям хочется, в толпу, В их утреннее оживленье.', 2),\n",
       " ('Я вышел на подмостки.', 2),\n",
       " ('На меня наставлен сумрак ночи Тысячью биноклей на оси.', 2),\n",
       " ('Если только можно, Авва Отче, Чашу эту мимо пронеси.', 2),\n",
       " ('Да, кстати.', 2),\n",
       " ('Вот они.', 2),\n",
       " ('Куда там!', 2),\n",
       " ('– Тсс.', 2),\n",
       " ('Наоборот.', 2),\n",
       " ('– Слушаюсь, барыня.', 2),\n",
       " ('«Женщина или ваза».', 2),\n",
       " ('Вашим.', 2),\n",
       " ('Родя!', 2),\n",
       " ('Я тороплюсь.', 2),\n",
       " ('– Что с тобой?', 2),\n",
       " ('– Что-то знакомое.', 2),\n",
       " ('Кока!', 2),\n",
       " ('Выносят.', 2),\n",
       " ('– Ну конечно.', 2),\n",
       " ('– Спасибо.', 2),\n",
       " ('Парило.', 2),\n",
       " ('Нет.', 2),\n",
       " ('Поразительно!', 2),\n",
       " ('Измен!', 2),\n",
       " ('Так.', 2),\n",
       " ('Ну хорошо.', 2),\n",
       " ('Слушайте.', 2),\n",
       " ('Видите?', 2),\n",
       " ('Вранье, хиромантия.', 2),\n",
       " ('Не слышу.', 2),\n",
       " ('Все в порядке.', 2),\n",
       " ('Прости.', 2),\n",
       " ('Да, представь себе.', 2),\n",
       " ('Ну как же!', 2),\n",
       " ('– Тоня!', 2),\n",
       " ('Быть не может!', 2),\n",
       " ('Какими судьбами?', 2),\n",
       " ('– Правильно.', 2),\n",
       " ('Ты подумай!', 2),\n",
       " ('Это азбука.', 2),\n",
       " ('Ну.', 2),\n",
       " ('– Ну как же!', 2),\n",
       " ('Поздно.', 2),\n",
       " ('Ты не спишь?', 2),\n",
       " ('Послушайте.', 2),\n",
       " ('Некогда.', 2),\n",
       " ('Под конвоем.', 2),\n",
       " ('– Ну да, ну да.', 2),\n",
       " ('Ей-богу, правда.', 2),\n",
       " ('– Здравствуйте.', 2),\n",
       " ('– Ладно.', 2),\n",
       " ('Запамятовал.', 2),\n",
       " ('Живаго...', 2),\n",
       " ('Странно.', 2),\n",
       " ('Гурьян!', 2),\n",
       " ('– Откуда?', 2),\n",
       " ('Будто из Демидовых мы.', 2),\n",
       " ('Что вы сказали?', 2),\n",
       " ('Однако продолжаю.', 2),\n",
       " ('Спасибо.', 2),\n",
       " ('Донат!', 2),\n",
       " ('Не знаю.', 2),\n",
       " ('– Нет, спасибо.', 2),\n",
       " ('Все может быть.', 2),\n",
       " ('Нам посчастливилось.', 2),\n",
       " ('Неужели правда?', 2),\n",
       " ('Надо торопиться.', 2),\n",
       " ('Ну так.', 2),\n",
       " ('– Не надо.', 2),\n",
       " ('Резолюцию!', 2),\n",
       " ('Домовой!', 2),\n",
       " ('Господи!', 2),\n",
       " ('– Нет, зачем.', 2),\n",
       " ('– Запамятовал.', 2),\n",
       " ('Третью беду сказывай.', 2),\n",
       " ('Толпа росла.', 2),\n",
       " ('Я знаю.', 2),\n",
       " ('Но мало того.', 2),\n",
       " ('– Погоди.', 2),\n",
       " ('Что ты делаешь?', 2),\n",
       " ('Как ты думаешь?', 2),\n",
       " ('Хорошо.', 2),\n",
       " ('Завтра утром...', 2),\n",
       " ('Лара!', 2),\n",
       " ('Уехали.', 2),\n",
       " ('Он открыл глаза.', 2),\n",
       " ('– Виноват.', 2),\n",
       " ('Больше я ее не видел.', 2),\n",
       " ('Как я выжил?', 2),\n",
       " ('Сомкнутые веки.', 2),\n",
       " ('Выси.', 2),\n",
       " ('Облака.', 2),\n",
       " ('Воды.', 2),\n",
       " ('Броды.', 2),\n",
       " ('Реки.', 2),\n",
       " ('Годы и века.', 2),\n",
       " ('Светало.', 2)]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent for sent in sorted_by_freq(sentences) if sent[1] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:26.797913Z",
     "start_time": "2020-11-09T16:23:26.783325Z"
    }
   },
   "outputs": [],
   "source": [
    "# какой самый частотный токен в тексте длиннее 6 символов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:27.976995Z",
     "start_time": "2020-11-09T16:23:27.804188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('андреевич', 289)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in sorted_by_freq(tokens) if len(word[0]) > 6][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:47:54.090998Z",
     "start_time": "2020-11-09T04:47:54.079997Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:47:55.807572Z",
     "start_time": "2020-11-09T04:47:55.788535Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:48:27.708281Z",
     "start_time": "2020-11-09T04:48:00.309189Z"
    }
   },
   "outputs": [],
   "source": [
    "stems = [(token, stemmer.stem(token)) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:48:27.723819Z",
     "start_time": "2020-11-09T04:48:27.712817Z"
    }
   },
   "outputs": [],
   "source": [
    "# два разных слова ошибочно свелись к одинаковой основе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:02:59.374688Z",
     "start_time": "2020-11-09T05:27:33.250327Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "same_stems_for_diff_tokens = [(stem, another_stem) for stem in stems for another_stem in list(set(stems))\n",
    "                              if stem[0] != another_stem[0] and stem[1] == another_stem[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T14:38:45.347159Z",
     "start_time": "2020-11-09T14:38:44.820195Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('не', 'не'), ('нее', 'не')), 2933),\n",
       " ((('не', 'не'), ('нею', 'не')), 2933),\n",
       " ((('не', 'не'), ('ней', 'не')), 2933),\n",
       " ((('он', 'он'), ('оно', 'он')), 1577),\n",
       " ((('он', 'он'), ('они', 'он')), 1577),\n",
       " ((('он', 'он'), ('она', 'он')), 1577),\n",
       " ((('он', 'он'), ('оной', 'он')), 1577),\n",
       " ((('как', 'как'), ('каки', 'как')), 1288),\n",
       " ((('как', 'как'), ('каков', 'как')), 1288),\n",
       " ((('как', 'как'), ('какому', 'как')), 1288),\n",
       " ((('как', 'как'), ('каком', 'как')), 1288),\n",
       " ((('как', 'как'), ('каким', 'как')), 1288),\n",
       " ((('как', 'как'), ('какою', 'как')), 1288),\n",
       " ((('как', 'как'), ('какого', 'как')), 1288),\n",
       " ((('как', 'как'), ('какая', 'как')), 1288),\n",
       " ((('как', 'как'), ('какую', 'как')), 1288),\n",
       " ((('как', 'как'), ('какой', 'как')), 1288),\n",
       " ((('как', 'как'), ('кака', 'как')), 1288),\n",
       " ((('как', 'как'), ('каких', 'как')), 1288),\n",
       " ((('как', 'как'), ('какими', 'как')), 1288),\n",
       " ((('как', 'как'), ('какие', 'как')), 1288),\n",
       " ((('как', 'как'), ('какое', 'как')), 1288),\n",
       " ((('это', 'эт'), ('этих', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этим', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этою', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этому', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этой', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('эту', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этими', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('эта', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этом', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('этого', 'эт')), 1001),\n",
       " ((('это', 'эт'), ('эти', 'эт')), 1001),\n",
       " ((('а', 'а'), ('ай', 'а')), 990),\n",
       " ((('по', 'по'), ('поили', 'по')), 964),\n",
       " ((('по', 'по'), ('поила', 'по')), 964),\n",
       " ((('из', 'из'), ('изо', 'из')), 796),\n",
       " ((('все', 'все'), ('всею', 'все')), 761),\n",
       " ((('все', 'все'), ('всей', 'все')), 761),\n",
       " ((('все', 'все'), ('всё', 'все')), 761)]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pair for pair in sorted_by_freq(same_stems_for_diff_tokens)][:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из частотных пар, подходящих под условие, ошибка в стемминге есть в следующих:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_((('не', 'не'), ('нее', 'не')), 2933),   \n",
    " ((('не', 'не'), ('нею', 'не')), 2933),   \n",
    " ((('не', 'не'), ('ней', 'не')), 2933),   \n",
    " ((('а', 'а'), ('ай', 'а')), 990),  \n",
    " ((('из', 'из'), ('изо', 'из')), 796)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первых трех из них у второй пары внутри каждой пары основа должна быть нулевой, а в четвертой и пятой парах у вторых пар основа должна быть одинакова с токеном."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:44.207072Z",
     "start_time": "2020-11-09T16:23:44.195424Z"
    }
   },
   "outputs": [],
   "source": [
    "# слово не изменилось после стемминга (слово должно быть русским и длиннее 4 символов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:44.455387Z",
     "start_time": "2020-11-09T16:23:44.364029Z"
    }
   },
   "outputs": [],
   "source": [
    "unchanged_tokens = [stem for stem in stems if stem[0] == stem[1] and \n",
    "                    len(stem[0]) > 4 and re.search(r'[а-яё]', stem[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:44.548429Z",
     "start_time": "2020-11-09T16:23:44.520198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('андреевич', 'андреевич'), 289),\n",
       " (('доктор', 'доктор'), 226),\n",
       " (('перед', 'перед'), 172),\n",
       " (('может', 'может'), 162),\n",
       " (('через', 'через'), 144),\n",
       " (('будет', 'будет'), 141),\n",
       " (('сейчас', 'сейчас'), 127),\n",
       " (('человек', 'человек'), 112),\n",
       " (('вдруг', 'вдруг'), 109),\n",
       " (('поезд', 'поезд'), 65),\n",
       " (('видел', 'видел'), 53),\n",
       " (('назад', 'назад'), 49),\n",
       " (('гордон', 'гордон'), 47),\n",
       " (('город', 'город'), 45),\n",
       " (('хотел', 'хотел'), 45)]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in sorted_by_freq(unchanged_tokens)][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из частотных пар, подходящих под условие, ошибка в стемминге есть у слов _может, будет, человек, видел, хотел_. Правильными основами были бы соответственно _мо, б,_ нулевая, _ви, хо_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T05:26:24.318110Z",
     "start_time": "2020-11-09T05:19:26.547Z"
    }
   },
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:47.003793Z",
     "start_time": "2020-11-09T16:23:46.991726Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:47.224167Z",
     "start_time": "2020-11-09T16:23:47.211397Z"
    }
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:47.781931Z",
     "start_time": "2020-11-09T16:23:47.761097Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "print(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на 100 самых частотных слов русского языка, собранные на основе данных НКРЯ, и проверим, какие из них отсутствуют в стоп-словах из библиотеки NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:48.976518Z",
     "start_time": "2020-11-09T16:23:48.952003Z"
    }
   },
   "outputs": [],
   "source": [
    "ruscorpora_freqs = ['и', 'в', 'не', 'на', 'я', 'быть', 'он', 'с', 'что', 'а', 'по', 'это', 'она', 'этот', 'к', 'но', 'они', 'мы', 'как', 'из', 'у', 'который', 'то', 'за', 'свой', 'что', 'весь', 'год', 'от', 'так', 'о', 'для', 'ты', 'же', 'все', 'тот', 'мочь', 'вы', 'человек', 'такой', 'его', 'сказать', 'только', 'или', 'ещё', 'бы', 'себя', 'один', 'как', 'уже', 'до', 'время', 'если', 'сам', 'когда', 'другой', 'вот', 'говорить', 'наш', 'мой', 'знать', 'стать', 'при', 'чтобы', 'дело', 'жизнь', 'кто', 'первый', 'очень', 'два', 'день', 'её', 'новый', 'рука', 'даже', 'во', 'со', 'раз', 'где', 'там', 'под', 'можно', 'ну', 'какой', 'после', 'их', 'работа', 'без', 'самый', 'потом', 'надо', 'хотеть', 'ли', 'слово', 'идти', 'большой', 'должен', 'место', 'иметь', 'ничто']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:49.567271Z",
     "start_time": "2020-11-09T16:23:49.555068Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['это', 'который', 'свой', 'весь', 'год', 'мочь', 'человек', 'сказать', 'время', 'говорить', 'наш', 'знать', 'стать', 'дело', 'жизнь', 'первый', 'очень', 'день', 'новый', 'рука', 'работа', 'самый', 'хотеть', 'слово', 'идти', 'большой', 'должен', 'место', 'иметь', 'ничто']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in ruscorpora_freqs if word.replace('ё', 'е') not in stops])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я бы добавила следующие слова, потому что они относятся к служебным частям речи, обладают высокой частотностью и потому невысокой информативностью и формы некоторых из них есть в списке NLTK, но почему-то нет их самых:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. _это_  \n",
    "2. _который_  \n",
    "3. _свой_  \n",
    "4. _весь_  \n",
    "5. _наш_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом список из NLTK нормальный, но странно было обнаружить, что как минимум пять перечисленных выше слов в нем отсутствуют и что некоторые слова есть не во всех формах, причем иногда слова нет в начальной, но есть в косвенных. Смущает, что совсем нет числительных и почти нет вводных слов. Лично я предпочитаю использовать список стоп-слов из библиотеки stop_words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T14:08:49.123775Z",
     "start_time": "2020-11-09T14:08:49.118775Z"
    }
   },
   "source": [
    "### Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:52.793265Z",
     "start_time": "2020-11-09T16:23:52.773090Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:54.000588Z",
     "start_time": "2020-11-09T16:23:53.991153Z"
    }
   },
   "outputs": [],
   "source": [
    "# лемматизируйте токены с помощью pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:54.606328Z",
     "start_time": "2020-11-09T16:23:54.493703Z"
    }
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:23:55.085031Z",
     "start_time": "2020-11-09T16:23:55.067607Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pymorphy2_lemmatized_text(tokens):\n",
    "    lemmatized_text = [(token, morph.parse(token)[0].normal_form) for token in tokens]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:24:01.993282Z",
     "start_time": "2020-11-09T16:23:55.898307Z"
    }
   },
   "outputs": [],
   "source": [
    "pymorphy2_lemmatized_text = get_pymorphy2_lemmatized_text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:24:02.024065Z",
     "start_time": "2020-11-09T16:24:01.999131Z"
    }
   },
   "outputs": [],
   "source": [
    "# лемматизируйте текст с помощью mystem3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:24:02.055165Z",
     "start_time": "2020-11-09T16:24:02.030093Z"
    }
   },
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:29:15.779663Z",
     "start_time": "2020-11-09T16:29:15.759542Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mystem_lemmatized_text(text):\n",
    "    lemmatized_text = [(lemma['text'], lemma['analysis'][0]['lex']) for lemma in mystem.analyze(text) \n",
    "                       if re.search(r'[а-яёa-z]', lemma['text']) and lemma['analysis']]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:29:30.839315Z",
     "start_time": "2020-11-09T16:29:16.389172Z"
    }
   },
   "outputs": [],
   "source": [
    "mystem_lemmatized_text = get_mystem_lemmatized_text(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T16:29:30.855253Z",
     "start_time": "2020-11-09T16:29:30.845171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Что в данном случае лучше для лемматизации mystem или pymorphy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на случаи, когда одни и те же токены библиотеки лемматизировали по-разному:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:06:30.942981Z",
     "start_time": "2020-11-09T16:29:30.864024Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_tokens = []\n",
    "pymorphy2_lemmas = []\n",
    "mystem_lemmas = []\n",
    "for pymorphy2_lemma in list(set(pymorphy2_lemmatized_text)):\n",
    "    for mystem_lemma in list(set(mystem_lemmatized_text)):\n",
    "        if pymorphy2_lemma[0] == mystem_lemma[0] and pymorphy2_lemma[1] != mystem_lemma[1]:\n",
    "            unique_tokens.append(pymorphy2_lemma[0])\n",
    "            pymorphy2_lemmas.append(pymorphy2_lemma[1])\n",
    "            mystem_lemmas.append(mystem_lemma[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:06:30.990983Z",
     "start_time": "2020-11-09T17:06:30.945982Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmas_comparison = pd.DataFrame({'Токен': unique_tokens,\n",
    "                                  'Лемма pymorphy2': pymorphy2_lemmas,\n",
    "                                  'Лемма mystem': mystem_lemmas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T18:06:12.235361Z",
     "start_time": "2020-11-09T18:06:12.213370Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Токен</th>\n",
       "      <th>Лемма pymorphy2</th>\n",
       "      <th>Лемма mystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>живее</td>\n",
       "      <td>живой</td>\n",
       "      <td>живо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>поворачиваясь</td>\n",
       "      <td>поворачиваться</td>\n",
       "      <td>повертываться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>запрокинувши</td>\n",
       "      <td>запрокинуть</td>\n",
       "      <td>запрокидывать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>повыгоднее</td>\n",
       "      <td>выгодный</td>\n",
       "      <td>выгодно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>федоровна</td>\n",
       "      <td>фёдор</td>\n",
       "      <td>федоровна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>прочее</td>\n",
       "      <td>прочее</td>\n",
       "      <td>прочий</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8009</th>\n",
       "      <td>побежден</td>\n",
       "      <td>победить</td>\n",
       "      <td>побеждать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>николаевну</td>\n",
       "      <td>николай</td>\n",
       "      <td>николаевна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>позвольте</td>\n",
       "      <td>позволить</td>\n",
       "      <td>позволять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8012</th>\n",
       "      <td>пораженный</td>\n",
       "      <td>поразить</td>\n",
       "      <td>поражать</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Токен Лемма pymorphy2   Лемма mystem\n",
       "0             живее           живой           живо\n",
       "1     поворачиваясь  поворачиваться  повертываться\n",
       "2      запрокинувши     запрокинуть  запрокидывать\n",
       "3        повыгоднее        выгодный        выгодно\n",
       "4         федоровна           фёдор      федоровна\n",
       "...             ...             ...            ...\n",
       "8008         прочее          прочее         прочий\n",
       "8009       побежден        победить      побеждать\n",
       "8010     николаевну         николай     николаевна\n",
       "8011      позвольте       позволить      позволять\n",
       "8012     пораженный        поразить       поражать\n",
       "\n",
       "[8013 rows x 3 columns]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:25:29.132122Z",
     "start_time": "2020-11-09T17:25:29.114082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.244247231602921"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmas_comparison) / len(tokens) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество токенов, которые были лемматизированы по-разному, составляет ~5.2% от общего числа, что, наверное, можно оценить как немного."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдения:  \n",
    "\n",
    "1. pymorphy2 хуже справляется с отчествами, он лемматизирует их как имя, от которого они образованы.  \n",
    "2. Часты разногласия по поводу вида глаголов, в том числе от которых образованы причастия: pymorphy2 предпочитает совершенный вид, mystem — несовершенный; кажется, что pymorphy2 чаще оказывается прав в этом пункте.  \n",
    "3. Проблема со сравнительной степенью наречий и прилагательных: без контекста не определить, образованы они от наречий или от прилагательных, а контекст посмотреть не представляется возможным; pymorphy2 чаще делает выбор в пользу прилагательных, mystem — наречий.\n",
    "4. pymorphy2 пишет \"ё\", mystem вместо \"ё\" пишет \"е\"; я думаю, что с \"ё\" информативнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я уверенно сказать, какая библиотека в данном случае лучше, но после оценки лемматизации случайных токенов из датафрейма выше кажется, что лучше pymorphy2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
