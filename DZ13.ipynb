{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0ea3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3b0ea3c",
    "outputId": "a8113f4d-4790-4919-c524-92fc43e973e9"
   },
   "outputs": [],
   "source": [
    "!apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650e9eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d650e9eb",
    "outputId": "92f96e9d-8a1a-4204-ecd5-f2a6dddef85f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tokenizers matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85a206",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac85a206",
    "outputId": "e1a010df-eea6-40ec-f904-b51b819b70e4"
   },
   "outputs": [],
   "source": [
    "# в vast ai или в последних версия jupyter может не работать автозаполнение, установка этой либы и перезагрука кернела помогает\n",
    "!pip install --upgrade jedi==0.17.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947b3313",
   "metadata": {
    "id": "947b3313"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cgMBidLNNf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77cgMBidLNNf",
    "outputId": "7d7bed31-4942-49c1-c033-86d54898ad29",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! wget -O opus.en-ru-train.en.txt http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oE-GlMuuLs0w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oE-GlMuuLs0w",
    "outputId": "b2c9d6be-a91e-49b0-87d2-add90971acba"
   },
   "outputs": [],
   "source": [
    "! wget -O opus.en-ru-train.ru.txt http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38911d06",
   "metadata": {
    "id": "38911d06"
   },
   "outputs": [],
   "source": [
    "# в русскоязычных данных есть \\xa0 вместо пробелов, он может некорректно обрабатываться токенизатором\n",
    "text = open('opus.en-ru-train.ru.txt').read().replace('\\xa0', ' ')\n",
    "f = open('opus.en-ru-train.ru.txt', 'w')\n",
    "f.write(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e110ff04",
   "metadata": {
    "id": "e110ff04"
   },
   "outputs": [],
   "source": [
    "en_sents = open('opus.en-ru-train.en.txt').read().lower().splitlines()\n",
    "ru_sents = open('opus.en-ru-train.ru.txt').read().lower().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb9b498",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eb9b498",
    "outputId": "9a5c649c-c718-41a1-fa69-2c372bb5b4a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('so what are you thinking?', 'ну и что ты думаешь?')"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sents[-1], ru_sents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0be060a4",
   "metadata": {
    "id": "0be060a4"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(BPE(), )\n",
    "tokenizer_en.pre_tokenizer = Whitespace()\n",
    "trainer_en = BpeTrainer(special_tokens=[\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[UNK]\", \"[MASK]\"], )\n",
    "tokenizer_en.train(files=[\"opus.en-ru-train.en.txt\"], trainer=trainer_en, )\n",
    "\n",
    "tokenizer_ru = Tokenizer(BPE())\n",
    "tokenizer_ru.pre_tokenizer = Whitespace()\n",
    "trainer_ru = BpeTrainer(special_tokens=[\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[UNK]\", \"[MASK]\"])\n",
    "tokenizer_ru.train(files=[\"opus.en-ru-train.ru.txt\"], trainer=trainer_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "496d0ea7",
   "metadata": {
    "id": "496d0ea7"
   },
   "outputs": [],
   "source": [
    "# раскоментируйте эту ячейку при обучении токенизатора\n",
    "# а потом снова закоментируйте чтобы при перезапуске не перезаписать токенизаторы\n",
    "tokenizer_en.save('tokenizer_en')\n",
    "tokenizer_ru.save('tokenizer_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4661964",
   "metadata": {
    "id": "f4661964"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
    "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc003758",
   "metadata": {
    "id": "dc003758"
   },
   "outputs": [],
   "source": [
    "def encode(text, tokenizer, target=False):\n",
    "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids + [tokenizer.token_to_id('[SEP]')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc2dae1",
   "metadata": {
    "id": "7fc2dae1"
   },
   "outputs": [],
   "source": [
    "X_en = [encode(t, tokenizer_en) for t in en_sents]\n",
    "X_ru = [encode(t, tokenizer_ru, target=True) for t in ru_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "281b5b90",
   "metadata": {
    "id": "281b5b90"
   },
   "outputs": [],
   "source": [
    "# max_len_en = np.mean([len(x) for x in X_en])\n",
    "# max_len_ru = np.mean([len(x) for x in X_ru])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5984886a",
   "metadata": {
    "id": "5984886a"
   },
   "outputs": [],
   "source": [
    "# max_len_en, max_len_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cc0a376",
   "metadata": {
    "id": "5cc0a376"
   },
   "outputs": [],
   "source": [
    "# ограничимся длинной в 20 и 22 (разные чтобы показать что в seq2seq не нужна одинаковая длина)\n",
    "max_len_en, max_len_ru = 20, 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f4f31fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f4f31fa",
    "outputId": "c1ccfe10-bf63-4a45-b276-a3ca9d3bf109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важно следить чтобы индекс паддинга совпадал в токенизаторе с value в pad_sequences\n",
    "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ae735e",
   "metadata": {
    "id": "49ae735e"
   },
   "outputs": [],
   "source": [
    "X_en = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "              X_en, maxlen=max_len_en, padding='post')\n",
    "X_ru_out = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "              [x[1:] for x in X_ru], maxlen=max_len_ru-1, padding='post', )\n",
    "\n",
    "X_ru_dec = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "              [x[:-1] for x in X_ru], maxlen=max_len_ru-1, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "824dcb29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "824dcb29",
    "outputId": "1bd9af03-8a60-40de-cd21-939b863c09a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 20), 1000000)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# миллион примеров \n",
    "X_en.shape, len(X_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25fa5f05",
   "metadata": {
    "id": "25fa5f05"
   },
   "outputs": [],
   "source": [
    "X_en_train, X_en_valid, X_ru_dec_train, X_ru_dec_valid, X_ru_out_train, X_ru_out_valid = train_test_split(X_en, \n",
    "                                                                                                      X_ru_dec, \n",
    "                                                                                                      X_ru_out, \n",
    "                                                                                                      test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "656be820",
   "metadata": {
    "id": "656be820"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"Calculate the attention weights. \"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4b51870",
   "metadata": {
    "id": "f4b51870"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # split heads\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # scaled dot-product attention\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # concatenation of heads\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c48cea2",
   "metadata": {
    "id": "5c48cea2"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, PAD_IDX), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21c0c899",
   "metadata": {
    "id": "21c0c899"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e120bbe5",
   "metadata": {
    "id": "e120bbe5"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68472627",
   "metadata": {
    "id": "68472627"
   },
   "outputs": [],
   "source": [
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89dcc42e",
   "metadata": {
    "id": "89dcc42e"
   },
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2f90e7c",
   "metadata": {
    "id": "a2f90e7c"
   },
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e9f89b8",
   "metadata": {
    "id": "8e9f89b8"
   },
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e356741b",
   "metadata": {
    "id": "e356741b"
   },
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                max_len,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "    # mask the future tokens for decoder inputs at the 1st attention block\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "    # mask the encoder outputs for the 2nd attention block\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size[0],\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "      max_len=max_len[0],\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size[1],\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "      max_len=max_len[1],\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size[1], name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c35ce0f",
   "metadata": {
    "id": "6c35ce0f"
   },
   "outputs": [],
   "source": [
    "L  = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none',)\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    loss = L(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, PAD_IDX), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6443d5c0",
   "metadata": {
    "id": "6443d5c0"
   },
   "outputs": [],
   "source": [
    "# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "#     from_logits=True, reduction='none')\n",
    "\n",
    "# def loss_function(real, pred):\n",
    "#   mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "#   loss_ = loss_object(real, pred)\n",
    "\n",
    "#   mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#   loss_ *= mask\n",
    "\n",
    "#   return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "# def accuracy(real, pred):\n",
    "#   accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "#   mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "#   accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "#   accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "#   mask = tf.cast(mask, dtype=tf.float32)\n",
    "#   return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "747835a8",
   "metadata": {
    "id": "747835a8"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "542fcc43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "542fcc43",
    "outputId": "1cdd4ab8-43ed-4525-bcc8-3655e87a4df8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# small model\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "\n",
    "# average model\n",
    "# NUM_LAYERS = 6\n",
    "# D_MODEL = 512\n",
    "# NUM_HEADS = 8\n",
    "# UNITS = 2048\n",
    "# DROPOUT = 0.1\n",
    "\n",
    "\n",
    "# Если доступно несколько гпу\n",
    "# расскоментируйте и сдвиньте остальной код ниже на 1 таб\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    model = transformer(\n",
    "        vocab_size=(tokenizer_en.get_vocab_size(),tokenizer_ru.get_vocab_size()),\n",
    "        num_layers=NUM_LAYERS,\n",
    "        units=UNITS,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout=DROPOUT,\n",
    "        max_len=[max_len_en, max_len_ru])\n",
    "\n",
    "#     learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "    def accuracy(y_true, y_pred):\n",
    "#         y_true = tf.reshape(y_true, shape=(-1, max_len_ru - 1))\n",
    "        return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model_ruen',\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=1,\n",
    "                                            save_weights_only=True,\n",
    "                                            save_best_only=True,\n",
    "                                            mode='min',\n",
    "                                            save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a8e81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "308a8e81",
    "outputId": "9f41f064-9527-4421-f2ad-02381910d9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  47/1188 [>.............................] - ETA: 9:28:23 - loss: 4.4469 - accuracy: 0.0467"
     ]
    }
   ],
   "source": [
    "# Обратите внимание на то как данные подаются в модель \n",
    "# помимо текста в модель еще нужно передать целевую последовательность\n",
    "# но не полную а без 1 последнего элемента\n",
    "# а на выходе ожидаем, что модель сгенерирует этот недостающий элемент\n",
    "# мы сравниваем выход из модели с целевой последовательностью уже с этим последним элементом\n",
    "\n",
    "# сдвинутые последовательности создаются выше\n",
    "# X_ru_dec - это переводной текст без последнего элемента\n",
    "# X_ru_out - это переводной текст с последним элементом\n",
    "\n",
    "model.fit((X_en_train, X_ru_dec_train), X_ru_out_train, \n",
    "             validation_data=((X_en_valid, X_ru_dec_valid), X_ru_out_valid),\n",
    "             batch_size=800,\n",
    "             epochs=100,\n",
    "             callbacks=[checkpoint]\n",
    "             )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41634b1f",
   "metadata": {},
   "source": [
    "(я не успела обучить трансформер, но думаю, что код ниже должен работать)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd785d",
   "metadata": {},
   "source": [
    "Задание:\n",
    "Нужно какое-то время пообучать трансформер для машинного перевода (те же данные что и на семинаре) и, используя, получившуюся модель перевести какой-то достаточно длинный текст на английском языке (например, какую-то новость). При этом нужно переделать функцию translate так, чтобы она обрабатывала не каждый текст по отдельности, а сразу целиком (или батчами если вы возьмете совсем длинный текст). На предложения текст можно поделить внутри или снаружи функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cwzoen7XXp_O",
   "metadata": {
    "id": "cwzoen7XXp_O"
   },
   "outputs": [],
   "source": [
    "!pip3 install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W-K_ISFRUGyq",
   "metadata": {
    "id": "W-K_ISFRUGyq"
   },
   "outputs": [],
   "source": [
    "from razdel import sentenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63762869",
   "metadata": {
    "id": "63762869"
   },
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    sents = list(sent.text for sent in sentenize(text))\n",
    "    translated_sents = []\n",
    "    for sent in sents:\n",
    "        input_ids = encode(sent.lower(), tokenizer_en)\n",
    "\n",
    "        input_ids = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                                          [input_ids], maxlen=max_len_en, padding='post')\n",
    "\n",
    "        output_ids = [tokenizer_ru.token_to_id('[CLS]') ]\n",
    "        \n",
    "        pred = model((input_ids, tf.cast([output_ids], tf.int32)), training=False)\n",
    "    \n",
    "        \n",
    "        while pred.numpy().argmax(2)[0][-1] not in [tokenizer_ru.token_to_id('[SEP]'), \n",
    "                                                                ]:\n",
    "            if len(output_ids) > max_len_ru:\n",
    "                break\n",
    "            output_ids.append(pred.numpy().argmax(2)[0][-1])\n",
    "            pred = model((input_ids, tf.cast([output_ids], tf.int32)), training=False)\n",
    "\n",
    "        translated_sents.append(' '.join([tokenizer_ru.id_to_token(i) for i in output_ids[1:]]))\n",
    "    \n",
    "    translated_text = ' '.join(translated_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2071b",
   "metadata": {
    "id": "a5e2071b"
   },
   "outputs": [],
   "source": [
    "text_to_translate = '''Почти год назад я переехал жить в Беларусь. Как вы уже догадались, если релокейт проходит без проблем, то такие истории на Хабр не пишутся. Однако, у меня есть что рассказать. Моя история будет не о славном граде Минске, белорусской идентичности, летних протестах и прочих, несомненно, важных вещах. Я расскажу вам об одной белорусской компании, в которой меня угораздило недолго поработать. История эта совершенно феерическая — что-то подобное могли бы снять режиссёры Silicon Valley. Всю свою карьеру я думал что так просто не бывает. Ну даже если и бывает — то я в это точно не вляпаюсь. Однако, я ошибался. Мне не повезло — переезд вышел мне боком и я влетел в целый водоворот событий. Они довольно поучительны и, как мне кажется, мой опыт будет интересен всем, кто планирует переезжать в ближайшем будущем. Меня зовут Павел и вот моя история.\n",
    "\n",
    "\n",
    "Последние десять лет я жил в небольшом городке под Новосибирском и работал через UpWork. Помимо этого я писал на Хабр и вёл два своих публичных открытых проекта: Reinforced.Typings и Reinforced.Tecture. Денег на жизнь мне хватало и времени на свои проекты оставалось достаточно. Но однажды положение дел изменилось. Стартап, в котором я работал — вырос, руководство начало размываться новыми людьми. В реорганизованной компании мне не нашлось места, и меня уволили. Само собой, я страдал, лез на стены, орал от несправедливости и зарекался навек работать без equity. Но жизнь показала, что бывает и хуже. Гораздо хуже.\n",
    "\n",
    "\n",
    "Я искал новую работу почти 4 месяца. Кроме удалёнки ничего не рассматривал. Однако, что-то упорно шло не по плану: на UpWork и до этого с C#/.NET было не густо, а в 2019 стало совсем печально. Мои пропозалы оставались без ответа, все свои коннекты я истратил. Remote на StackOverflow был только для обладателей паспорта США, а личные контакты и нетворкинг молчали. Моя финансовая подушка таяла, и скрепя сердце, я принял решение выйти из зоны комфорта и наконец-то релоцироваться из того медвежьего угла, в котором сидел последние 10 лет.\n",
    "\n",
    "\n",
    "На Европы и Америки у меня не было ни денег ни связей. Работать спустя рукава в аутсорсе я решительно не хотел. Питер мне просто не нравится. В Москве дорого, пафосно, пробки и огромные расстояния. При этом цивилизации вокруг все равно хотелось. Ну стрёмно мне тратить 20 баксов и 3 часа на такси туда-обратно до ближайшего нормального бара. Ещё хотелось, чтобы IT-индустрия жила и шевелилась. Митапы всякие там, конференции, барные тусовки. Да и в целом — к 10+ годам индустриального опыта хочется уже работать с профессионалами своего дела, а не с недоучками.\n",
    "\n",
    "\n",
    "Мои знакомые посоветовали Минск. Я знал, что в Республике Беларусь действует ПВТ и зарплаты весьма привлекательны. Более того — есть несколько примечательных продуктовых компаний: Viber, Stimulsoft, Pandadoc, Mapbox и TargetProcess имени Михаила Дубакова. В последней была открыта вакансия C#-разработчика и я отправил туда резюме. Я уже слышал про эту компанию — их продуктом пользовались мои хорошие знакомые из Новосиба. Компания быстро откликнулась на моё письмо, я прошел совершенно стандартное собеседование с тестовым заданием и, наконец, получил оффер.\n",
    "Я перестраховщик, так что пособеседовался и в другие компании — это дало мне ещё один оффер. Пришлось долго и мучительно выбирать между двумя вариантами, и в итоге я выбрал TargetProcess. Его коллектив показался мне вполне нормальным и, что немаловажно, профессиональным. Гугл ничего плохого про компанию не выдавал — только радужные статьи на dev.by, где гордо рассказывается как компания справляется с процессом разработки без менеджеров и даже HR-ов. На собеседовании я тоже не заметил, что что-то может пойти не по плану.\n",
    "\n",
    "\n",
    "Новосибирск — Минск\n",
    "\n",
    "Оффер я принял и пообещал, что как штык буду на рабочем месте 10 декабря, в 11 утра. Но переезд дался мне нелегко. Обычно я не склонен к сантиментам, но тут было прямо не по себе. Деньги кончались, разработка своих проектов встала, а в Беларуси у меня нет решительно никого из знакомых. Я, блин, всё бросаю и еду в никуда. Срываюсь с насиженного места под влиянием обстоятельств. Всё, что у меня есть — это моя голова на плечах, технический опыт и вот этот оффер в инбоксе. Добираться предстоит совершенно одному. Случись что, помощи просить не у кого, вся надежда только на себя. Я старался себя успокоить тем, что TargetProcess вроде адекватная компания и уж точно не допустит какого-нибудь непотребства.\n",
    "\n",
    "\n",
    "Сдал квартиру, доверил своего кота ответственому знакомому, выкинул ненужный хлам, что-то продал. Прекратил ходить на тренировки и сбрасывать вес, попрощался с немногочисленными друзьями. Единственное, что я себе оставил — автомобиль. Заднеприводный бизнес-кореец, продать который за вменяемую цену в Новосибирске мне не удалось. Сдавать своего коня перекупам по бросовой цене я категорически не желал. К чёрту. Занял денег у хороших людей и взял его с собой. Ближайший год мне всё равно не светило возвращаться (рекрутёр TargetProcess меня заверила что люди в этой компании работают подолгу — как раз то, что нужно).\n",
    "\n",
    "\n",
    "Колёса пришлись весьма кстати. Я упаковал в багажник всё, что хотелось взять с собой, поставил на автовоз в Москву, а сам вылетел следом.\n",
    "\n",
    "\n",
    "От Москвы до Минска надо было ехать своим ходом. Мне не впервой гонять на дальние расстояния по трассе, но и тут не без факапа. Автомобиль, заляпанный сантиметровым словом грязи, мне отгрузили с автовоза позже планируемого. Мойка, оплата, МКАД — и вместо расчётных 10 утра, я выехал чуть ли не в час дня. Про разницу в широтах и время захода солнца я, конечно же, был не в курсе. В общем, в 5 вечера прямо на трассе меня застала глухая ночь и дождь со снегом. Не самые удобные условия для вождения, но отступать уже некуда. Ехал наощупь, пытаясь не слететь с дороги.\n",
    "\n",
    "\n",
    "А после пересечения Российско-Белорусской границы у меня отвалилась связь. Местную SIM-карту взять негде, пришлось вести по кэшированному куску яндекс.карт, указателям и километровым столбам. Часам к 11 вечера, наглухо вымотавшись, преодолев 4.5 тысячи километров за день, я наконец въехал в Минск. Вызвонил арендодателя (дай ей б-г здоровья!), с которой договорился заранее. Втащил вещи в квартиру и наконец грохнулся спать.\n",
    "\n",
    "\n",
    "10 декабря, 11 утра. Я явился в офис и...\n",
    "\n",
    "\n",
    "Хоп!\n",
    "\n",
    "Проходит две недели. Я почти закрывая свою первую задачу (разгребание инфраструктурного легаси системы), только-только начинаю отходить от переезда, как вдруг...\n",
    "\n",
    "\n",
    "меня уволили.\n",
    "26 декабря 2019го года, под новогодние праздники я остался без работы.\n",
    "\n",
    "\n",
    "Из денег у меня — зарплата за месяц (даже долги не вернёшь), вокруг — чужая страна, чужой город в предпраздничном ажиотаже. Проводить собеседования до 15 января никто не собирается, в городе введён режим \"давай после праздников\". До России — 600 километров, до дома вообще пол-Земли. Я даже не могу зарегистрироваться по месту пребывания — нужен трудовой договор — и любой встречный милиционер имеет полное право взять меня за жопу.\n",
    "\n",
    "\n",
    "Никаких \"профилактических бесед\" со мной не проводили, претензий к моей работе не возникало, методических рекомендаций, что сделать лучше или по-другому — не поступало. Создалось ощущение, что компании я просто не упёрся. Технически это выглядело так: Андрей Хмылов — человек, который что-то вроде тимлида в команде отозвал меня в сторонку и сказал \"мы решили не продолжать с тобой, потому что что-то мы не срабатываемся\". На вопрос \"А зачем вы вообще меня наняли?\", я получил предельно чёткий ответ: \"Просто мне показалось, что процессы в моей команде масштабируются на 6 человек, а не на 5\".\n",
    "\n",
    "\n",
    "Ну вы понимаете — человеку показалось.\n",
    "\n",
    "\n",
    "Через 2 дня у меня состоялся диалог с техническим директором TargetProcess — Евгением Хасеневичем. И он был куда богаче на детали:\n",
    "\n",
    "\n",
    "— В договоре чётко прописан испытательный срок, а проработал я 2 недели. Что значит \"мы не срабатываемся\"?\n",
    "— По трудовому кодексу Беларуси мы имеем право уволить тебя на испытательном сроке когда захотим.\n",
    "— Хорошо, я не эксперт в белорусском законодательстве. Но эм… я не в самом удачном положении — только переехал, у меня одни долги.\n",
    "— Ну я не уточнил в бухгалтерии, можно ли заплатить тебе за 2 недели, поэтому компания — обрати внимание — закроет на это глаза и выплатит тебе месячную зарплату.\n",
    "— То есть я ещё и спасибо сказать должен?\n",
    "— Спасибо говорить не надо. Считай что это такая… добрая воля компании.\n",
    "— Ещё раз: я одолжил больше денег, чтобы к вам приехать, чем то, что вы мне пишете в расчётном листке.\n",
    "— А за что тебе платить? — собеседник расплылся в улыбке — Давай ты напишешь смету, я отнесу её в бухгалтерию, там всё посчитают.\n",
    "— Я… э…\n",
    "— Ну а что ты хотел? Переезд — это всегда риски, ты должен быть к ним готов.\n",
    "— Так на дворе новогодние праздники. Мне придётся сидеть без работы месяц, потому что никто не собеседует.\n",
    "— Ну если ты хороший программист, то в Минске-то без проблем найдёшь себе работу.\n",
    "Рекрутёр TargetProcess порекомендовала мне не лезть на рожон. Скрепя сердце, я подписал доп. соглашение, что де-факто означало увольнение по собственному. Страна чужая, я только переехал — мне реально было стремно качать права.\n",
    "\n",
    "\n",
    "Где-то тут пришло понимание, что соглашаться на релокейт \"в ручном режиме\" было довольно глупой затеей. Но издалека сотрудники TargetProcess не создавали впечатление безответственных мудаков, и мне чудилось, что я знаю на что иду. Пожалуй, надо завязывать с доверчивостью.\n",
    "\n",
    "\n",
    "Я не переношу вранья и нарушения договорённостей. А здесь было целое комбо: внезапно выяснилось что никто мне ничего не обещал, а руководство продемонстрировало мне беспрецедентное хамство и выставило всё так, будто мне с барского преча позволили тут поработать. Человек, занимающий должность CTO, откровенно посмеялся мне в лицо. То есть меня, неплохого и опытного инженера, который в силу обстоятельств пошёл навстречу компании — облили говном и поставили в крайне неудобную ситуацию. Я считаю что во взрослом мире так дела не делаются. Раз компания в лице технического директора позволяет себе такое поведение, то мне ничего не мешает трактовать это инцидент как… ммм… дайте-ка посмотрю на свой банковский счёт… Точно! Кидалово на бабло.\n",
    "\n",
    "\n",
    "Почему эта статья должна быть здесь?\n",
    "\n",
    "В нашей индустрии есть ненадёжные люди. Мне кажется, что информация об их боевых заслугах обязана быть доступна по первому же поисковому запросу. Она должна светиться яркой неоновой вывеской. Чтобы любой желающий незамедлительно понял, кто есть кто, и на кого можно положиться в тонких вопросах переезда, а на кого нет. В случае с TargetProcess ситуация такова: поисковая выдача пестрит красивыми заголовками статей и интервью, описывающими радужно-конфетный мир. В объективной же реальности компания допускает крайне неэтичное отношение к релоцировавшимся сотрудникам. И я тому пример. Намеренно вводить людей в заблуждение — это очень и очень скверно.\n",
    "\n",
    "\n",
    "Остаться без денег перед праздниками в чужой стране — это не та ситуация, в которую каждый из нас хочет попасть. Ладно, я — не голодающий Поволжья. Да и решать сложные проблемы мне не впервой. А если кто-то купится на оффер и приедет издалека с семьёй? С детьми? А если это будет молодой разработчик, который даже не подозревает о том, что так вообще бывает? Разумнее будет сократить риски, когда есть возможность и быть в курсе последствий.\n",
    "\n",
    "\n",
    "Если бы эта статья была у меня-из-прошлого, я бы сэкономил кучу денег и нервов.\n",
    "\n",
    "\n",
    "Жаль что опубликовать эту информацию раньше у меня не дошли руки. Просто они дрожали. И ещё глаз дёргался. Только сейчас я более-менее справился с тревожным расстройством и коробкой неврозов, которые мне достались всего после двух недель сотрудничества с героями статьи. Даже среди ночи уже не просыпаюсь. Почти. Ну что, вы всё ещё выгораете?\n",
    "\n",
    "\n",
    "Тогда я вам расскажу как устроены стильные-модные-молодёжные компании.\n",
    "\n",
    "\n",
    "\n",
    "Дело в том, что TargetProcess и её сотрудники свято чтят soft skills. Они очень любят рассказывать о себе. Например о том, как они обходятся без менеджеров и директора по управлению персоналом, какой у них стильный офис и как они получили ажно $5 млн инвестиций. Выходят хвалебные статьи, основатель активно визионирует, а члены самой-звёздной-команды выкладывают в командный инстаграмм фотографии с котлетами бабла. Короче, все при деле — \"мы продуктовая компания, а не вот эти вот… ГАЛЕРЫ\", \"мы как белорусский Google!\".\n",
    "\n",
    "\n",
    "С самого начала у меня было какое-то внутреннее ощущение что дело тут нечисто. При таких замашках надо действительно быть стоящим игроком. Я насторожился, но в итоге списал всё на \"должно быть я что-то не понимаю\". Кажется, это называется эффект Даннинга-Крюгера. Но пост-фактум все странности становятся очевидны и я долго ругал себя за невнимательность.\n",
    "\n",
    "\n",
    "Собеседование в TargetProcess квалификацию особо не проверяет, что явно не уровень продуктовой компании. Пусть так — у меня есть Github-аккаунт, у меня есть Хабр, у меня есть UpWork с отзывами, мою квалификацию можно проверить тысячью и одним способом, не задавая глупых вопросов про GetHashCode.\n",
    "\n",
    "\n",
    "Чего действительно не ожидаешь от места, где \"важны soft-skills\" — собеседуют одни люди, а в команду попадаешь совершенно к другим. Уже это должно было стать красным флагом, но я, видимо, слишком наивен.\n",
    "\n",
    "\n",
    "От момента, как я принял оффер до моего фактического приезда прошёл МЕСЯЦ. 30 дней. Четыре рабочих недели. Если компания декларирует упор на общение и софт-скиллы, то за эти 30 дней можно было организовать бесчисленное количество онлайн-встреч, посмотреть на меня через камеру, поговорить со мной текстом, голосом, познакомиться, выпить через skype в конце концов, дать тестовую задачу. Да господи, хоть онбординг провести и сказать мне по итогу — мол, нет, чувак, извини, не подходишь. Просто чтобы не дёргать меня через пол-страны и не жечь мои деньги. Но ничего из этого компания не сделала.\n",
    "\n",
    "\n",
    "Кстати, про онбординг.\n",
    "\n",
    "\n",
    "— Чем я могу помочь команде? Давайте для ознакомления я починю несколько застарелых багов, чтоли. Руки чешутся.\n",
    "— Это так не работает — ответил мне человек, играющий в тимлида\n",
    "— А как оно работает?\n",
    "— Ну… не знаю… Я ожидаю некой автономности от своих сотрудников… Ну возьми разгреби воон ту штуковину.\n",
    "Вот и весь тебе онбординг в устах Андрея Хмылова. Замечательный процесс, заточенный под быстрое и эффективное введение новых людей в работу над кодовой базой с более чем 15-летней историей. Особое внимание стоит обратить на заинтересованность, ответственность и готовность помочь.\n",
    "\n",
    "\n",
    "Помогает в процессе онбординга полностью отсутствующая документация. Кусочек readme.md в репозитории, где-то документ в облаке, где-то заметка в личном блоге, где-то схема в онлайн-рисовалке, ссылка на которую передаётся из уст в уста. Передавать из уст в уста — наиболее общепринятый способ распространения информации о системе. Намеренно объяснять никто ничего не собирается — \"ожидается автономность от сотрудников\" (с).\n",
    "\n",
    "\n",
    "Общего списка всех репозиториев, ссылок на них и объяснения, что в них есть — так же нигде нет. Системный администратор сделает вам пользователя чтобы вы могли залогиниться на свою рабочую машину — всё остальное в режиме \"ну… попроси кого-нибудь\". Вместо назначения ответственных за процесс принимается гениальное управленческое решение — закрыть информационные дыры с помощью soft-skills. Браво, узнаю управленческие практики google.\n",
    "\n",
    "\n",
    "Какая ирония: компания, делающая инструмент для управления процессами разработки не может наладить процессы разработки сама у себя. Как это вообще блин работает?\n",
    "Это очень похоже на job security driven development. Намеренно ограничивать знания о системе, чтобы никого не рискнули уволить и зарплату повышали не из-за профессиональных качеств, а потому что \"никто же больше в этом не разберётся!\". Страх, что \"в системе больше никто не разберётся\" довольно распространён в нашей сфере, но давайте замнём для ясности и коротко пройдёмся по самой системе чтобы понять, так ли всё плохо.\n",
    "\n",
    "\n",
    "Система\n",
    "\n",
    "Процессный и организационный бардак ни о чём не говорит при условии, что сама система сделана на совесть. Но\n",
    "\n",
    "\n",
    "\"Любая организация, проектирующая систему неизбежно создаст такую модель, которая будет повторять коммуникационную структуру самой организации\".\n",
    "— Закон Конвея.\n",
    "Старик Конвей и здесь оказался прав.\n",
    "\n",
    "\n",
    "Первое, что я увидел — единого кода системы не существует. Есть разные куски, написанные в разное время, разными людьми, с разными взглядами и разными убеждениями по вопросу \"как надо\". Разумеется, все они уже уволились, онбордить сотрудников никто не планирует, поэтому разбираться надо с нуля.\n",
    "\n",
    "\n",
    "Если долго всматриваться в этот код, то создаётся впечатление, что авторы не проблему решали и не фичи делали, а показывали какие они умные. Что они знают паттерн strategy, или пробуют новый фреймворк за счёт работодателя, или новый язык, или просто креативят в пустоту. По итогу проблемы (зачастую выдуманные) решаются наименее очевидным из всех возможных способов. Технологические понты. Как и бывает в таких случаях, инструментарий авторы не понимали и не утруждали себя погружением в детали на предмет зачем это нужно, как оно работает и к месту ли. Что закономерно, ведь, как и было сказано, важны soft-skills. А стало быть на хрен идут проблемы продукта — тут надо показать коллегам какой ты умный и красивый. Вершина и кульминация этого буйства сознания — использование самописной монады Maybe<>, которая где-то в середине стека вызовов прагматично разворачивается в if (maybe.HasValue). Функциональное программирование вам, так сказать, в production.\n",
    "\n",
    "\n",
    "Выстроив в голове модель сущностей, открываешь для себя другую особенность. Называется \"без штанов, но в шляпе\". Приведу абстрактный пример: вообразите себе витиеватые заросли Repository Pattern, всё по науке, интерфейс-реализация, в разных неймспейсах, с заделом на тестирование. Вот вся эта красота развешена поверх… статического подключения к БД! Такое нам в Новосибирск из Индии везут на рефакторинг! Тоннами! Я ещё будучи джуном понял, почему подключение к БД нельзя пихать в статический контекст. Что же помешало \"лучшим умам\" не наступить на эти грабли? Видимо, тот факт что про грамотное управление лайфтаймом подключения не расскажешь на тим-митинге и внутренней конфе. А вот прочитать статью на википедии и красиво всё разложить по репозиториям — вполне себе социально одобряемое. Десять soft skills из десяти.\n",
    "\n",
    "\n",
    "Обычно подобный треш и угар в системе пресекается системным архитектором. Но это не наш случай: в дополнение к soft-skills, тут полный agile. То есть предполагается, что все сотрудники — профессиональные инженеры, которые сами могут договориться и принять правильное техническое решение. Вкусно, как Orbit со вкусом design by committee.\n",
    "\n",
    "\n",
    "Видавший виды руководитель знает, что agile и делегирование принятия технических решений команде на практике означает \"слабоумие и отвага\", если не проводить жесточайшего кадрового отбора по хард-скиллам. Но чтобы организовать такой отбор во-первых нужен человек неприлично высокой квалификации, который и будет проводить собеседование, а во-вторых — опытный управленец с намётанным глазом.\n",
    "\n",
    "\n",
    "В рамках своей первой и единственной задачи я разгребал код, написаный местным техническим директором. Что ж… если человек не может спроектировать простое консольное приложение, принимающее флаги и делающее действия, то строгий кадровый отбор по хард-скиллам — явно история не про него. Вот и остаётся писать в буклетах \"процесс разработки не нуждается в менеджерах\" и загадочно улыбаться.\n",
    "\n",
    "\n",
    "Сам по себе отвратительный код — это нормально. Для какого-нибудь аутсорса. Разница в том, что аутсорс-компания обычно не претендует на лавры best place for work и какой-то особый уровень экспертизы. Да и лица там не настолько высоконагружены, чего греха таить.\n",
    "\n",
    "\n",
    "Кстати, о лицах\n",
    "\n",
    "Вообще я не очень хорошо разбираюсь в людях, предпочитаю всё-таки системы. Но тут сам б-г велел, ведь радужно-оптимистичные статьи жанра \"личностный рост для разработчика\" предписывают работать с талантливыми людьми. Сам не читал, но что-то такое слышал на краю Интернета. Грех не воспользоваться случаем.\n",
    "\n",
    "\n",
    "И вот впервые в жизни я увидел молодых мальчиков и девочек с высокодуховными лицами, лоснящихся от высоких зарплат. Они не ходят, они как будто парят над землёй, стоя на облаке из квалификации. Ну, думаю, наконец-то. Вот они — настоящие инженеры. Сбылась мечта идиота, я работаю не с аутсорс-недоучками и вайтишниками, а с самыми, что ни на есть мозгами. Которые в курсе трендов и технологий!\n",
    "\n",
    "\n",
    "Я обратился к людям из \"самой звёздной команды\"(tm) в попытке поговорить с ними о технических штуках, рассказать о том, через что сам прошёл, обсудить тенденции, архитектуры разных вещей (в том числе и самой системы)...\n",
    "\n",
    "\n",
    "Видимо, что-то пошло не так. В ответ я получил пачку и без того мне известных buzzword-ов, одухотворённо-покровительственный взгляд и отшучивание. Всю первую неделю я гадал — что же не так? Может я как-то… не знаю… Вопросы не те задаю? Или, может, надо не про себя рассказывать, а больше вопросов задавать, попросить научить меня чему-нибудь?\n",
    "\n",
    "\n",
    "Всё оказалось гораздо проще. Технические дискуссии коллег не интересуют. Поначалу казалось что их вообще мало что интересует, но потом я просёк фишку. \"Высоконагруженные лица\" оживляются на разговорах о чём-то более мирском. Ну вы знаете, не об этих ваших абстракциях, паттернах и технологиях, а о чём по-проще: кто в каком ресторане обедал, где провести тимбилдинг, куда поехать в отпуск, кто какой гаджет купил и прочие темы \"за жизнь\" \"за покупку второй бэхи\".\n",
    "\n",
    "\n",
    "Тут у меня, наверное, нет комментариев. Видимо вот такой он, градус дискуссии профессионалов высокого класса. И ничего с этим не поделаешь.\n",
    "\n",
    "\n",
    "Итог\n",
    "\n",
    "Вот что мне всю жизнь непонятно — почему инвесторы вкладываются в такие компании? Предположим, что у меня были бы деньги на долю и я хочу разобраться: а что тут, собственно, покупать? Обычно в стартапах покупают рост в надежде, что он будет взрывной. Но взрывной рост сложно организовать без продукта, попадающего в голубой океан пользовательских потребностей. Здесь требуются удачливые визионеры, грамотные маркетологи, Product Manager-ы и работающий как часы продакшен.\n",
    "\n",
    "\n",
    "В TargetProcess: единственный визионер (он же основатель, он же Миша Дубаков) ушёл с продукта, плотняком ударился в идею околокорпоративного no-code. TargetProcess после этого начал заниматься хаотичным метанием в надежде догнать Jira под руководством каких-то сомнительных личностей.\n",
    "\n",
    "\n",
    "Продакшен? Увы, поверхностный аудит кода и разговор с людьми отчётливо показал что продакшен больше интересует красивая жизнь, нежели продукт или технологии.\n",
    "\n",
    "\n",
    "Взрывной рост сложно пережить без чёткого управления и подготовленных процессов. Здесь уровень разгильдяйства вкупе с возрастом предприятия даёт явное понимание что людей, способных внедрить и настроить процессы в компании нет и никогда не было. Документация, онбординг, ответственные, передача информации? По всем пунктам провал. Взрывной рост разорвёт всю конструкцию на куски по наложенным на коленке швам.\n",
    "\n",
    "\n",
    "Однако TargetProcess не уникален. Подобных компаний на рынке полно. Думаю, будет не лишним написать пару советов как не угодить в местечковый Theranos.\n",
    "\n",
    "\n",
    "Как не наступить на мои грабли\n",
    "\n",
    "Я детально переварил свой опыт, поговорил со знакомыми из кадрового бизнеса, расспросил успешно релоцировавшихся как прошло у них, почитал интернет. На основе полученной информации я составил свой список основных моментов, которые необходимо учитывать при релокации. Как видите, откровенный трешак, маскирующийся под серьёзный бизнес на рынке присутствует, поэтому надо держать ухо востро, чтобы не оказаться в жопе. Мне видится так, что эта информация, написанная моими нервами, деньгами и психическим здоровьем будет полезной для желающих переехать. Да и в целом держите это в голове при любой смене места работы.\n",
    "\n",
    "\n",
    "Первое, что надо помнить при релокейте — вы в заведомо более рисковом положении, нежели компания. У вас меньше и денег, и времени, и нервов. И правовое поле не ваше, и территория чужая. Вы в максимально уязвимом положении. Кинуть вас и оставить ни с чем — проще, чем отобрать леденец у ребёнка. Поэтому надо выбивать из принимающей стороны максимальные бонусы. Это не \"программисты зажрались\", а необходимая мера страховки для обеих сторон: вы худо-бедно приобретаете уверенность, что даже если что-то пойдёт не так — вы не окажетесь один на один с полной жопой. Компания вкладывая деньги в ваш переезд, верифицирует управленческое решение и страхует себя от негативных отзывов в будущем. Короче, даже не начинайте диалог о релокации без обсуждения релокейшн-пакета и даже не пытайтесь обеспечить его своими руками, если компания не предлагает. Серьёзно, просто не надо.\n",
    "\n",
    "\n",
    "В рамках релокейшн-пакета требуйте:\n",
    "\n",
    "\n",
    "Полную или частичную оплату переезда. Как минимум билет в одну сторону вам должны оплатить. Совсем прекрасно если вас встретят в аэропорту или куда вы там прибываете;\n",
    "Временного размещения. Требуйте предоставления корпоративной квартиры или отеля на период, пока вы не найдёте постоянное жильё. Совсем хорошо если компания помогает с поисками;\n",
    "Relocation bonus. Чтобы к первым вашим зарплатам была прибавка на основе тот факта, что вы переехали. Обычно у переехавших с деньгами не очень, поэтому помощь компании необходима. Совсем хорошо если бонус единовременный и выдаётся сразу;\n",
    "Серебряный парашют. Редко, но такое бывает. Это формальное обязательство выплатить вам компенсацию (обычно в размере нескольких зарплат) в случае увольнения в первые 1-2-6-12 месяцев (как договоритесь);\n",
    "Оформления приглашений, виз (в том числе для членов семьи), страховок и прочих въездных и не очень документов. В идеале — без вашего участия.\n",
    "\n",
    "Удостоверьтесь заранее:\n",
    "\n",
    "\n",
    "Что google, GlassDoor, любые сайты с отзывами не выдают о компании ничего плохого. Если есть хоть один (один!) негативный отзыв — ищите другой вариант. Поверьте, это не та рулетка, в которую вам стоит играть;\n",
    "Что в целевой компании есть отработанный процесс онбординга новых сотрудников;\n",
    "Что трудовой договор не подразумевает расторжения ранее определённого срока (так же именуемого испытательным);\n",
    "Что компания ранее уже занималась трудоустройством релоцирующихся сотрудников. Это чтобы в самый неподходящий момент кадровики и бухгалтеры не начали судорожно звонить в миграционную службу и узнавать какой пакет документов, в какие сроки и куда надо предоставить. Совсем хорошо если у компании есть опыт релокации именно из вашей страны;\n",
    "Что вы будете работать именно с теми людьми, которые вас собеседовали;\n",
    "Что мотивация вашего найма — не \"абы взять\" на потеху инвестора, а необходимость решения конкретных проблем нанимающей стороны. Спрашивайте явно на собеседовании — \"зачем вы меня нанимаете? какая у вас конкретно боль?\";\n",
    "Что у компании есть чёткая и понятная всем сторонам политика увольнений.\n",
    "\n",
    "Вообще, про увольнения, конечно, я рекомендую прямо сейчас поговорить с вашим руководством. Поймайте своего непосредственного начальника за пуговицу и добейтесь ответа на вопрос \"при каких условиях вы меня уволите\"? Один мой хороший знакомый предложил отличную формулировку: \"какое моё поведение приведёт к вашему решению о моём увольнении?\". Тут самое страшное — даже не жёсткость условий, а определённость, с которой вам дали ответ. Помните — если руководитель не понимает за что людей надо увольнять, а за что — нет, то вы будете уволены в самый неожиданный момент по самой неожиданной причине. Совсем хорошо будет сопоставить ответ на этот вопрос с трудовым законодательством целевой страны. Если политики увольнения в компании нет, то это легитимная причина для пересмотра вашей зарплаты в сторону повышения в связи с необходимостью покрытия рисков. Или смены работы на место, где управлять умеют немного лучше.\n",
    "\n",
    "\n",
    "Послесловие\n",
    "\n",
    "Я хочу поблагодарить ребят из подкаста \"Мы обречены\" и Филу лично за то, что не остались глухи к моей ситуации и сильно помогли мне успокоиться, взять себя в руки и написать слаженный текст о произошедшем. Спасибо, ребята, без вас я бы не справился — совсем одному переживать такое было бы крайне тяжело. Эта история слишком сильно меня подкосила и выбила из колеи, но с вашей помощью я выгреб.\n",
    "\n",
    "\n",
    "В феврале я нашёл другую работу и мои нынешние коллеги, должность и зарплата меня очень радуют.\n",
    "\n",
    "\n",
    "Потом случился коронакризис. А потом, летом в Беларуси произошли всем известные события. Не смотря на подпорченное первое впечатление, мне посчастливилось встретить очень много совершенно прекрасных людей, поддержать их в меру возможностей и посодействовать им. Беларусь прекрасна, белорусы абсолютно замечательные. Но, как и в любом обществе, здесь так же есть и хитрые шарлатаны, и безответственные дураки, которым нельзя доверять и проходимцы от IT-индустрии, возомнившие себя мессиями. Я категорически не желаю чтобы персонально мой негативный опыт и конкретно TargetProcess бросал тень на всё белорусское IT. Тот факт, что лично мне попалась чудовищно токсичная компания с непрофессиональным руководством, вовсе не означает, что везде так. Нет.\n",
    "\n",
    "\n",
    "В Беларуси полно замечательных кадров, интересных компаний, умных и достойных людей. Видимо, я просто крайне неудачно выбрал представителей индустрии для начала работы.\n",
    "\n",
    "\n",
    "Берегите себя.\n",
    "\n",
    "\n",
    "P.S: совсем забыл подсветить ещё один маленький, но интересный момент. Сразу после инцидента вакансия разработчика на сайте TargetProcess поменялась с Senior на Junior. А через некоторое время и вовсе исчезла. Вот теперь всё.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N_Z8xB8hXmUo",
   "metadata": {
    "id": "N_Z8xB8hXmUo"
   },
   "outputs": [],
   "source": [
    "translate(text_to_translate)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "MT_transformer_tf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
