{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7ba721",
   "metadata": {},
   "source": [
    "### Задание 1. (5 баллов) \n",
    "\n",
    "В тетрадке реализована биграмная языковая модель (при генерации учитывается информация только о 1 предыдущем слове). Реализуйте триграмную модель и сгенерируйте несколько текстов. Сравните их с текстами, сгенерированными биграмной моделью. \n",
    "Можно использовать те же тексты, что в семинаре, или взять какой-то другой (на английском или русском языке).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864493b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:18.098893Z",
     "start_time": "2021-06-26T14:35:17.559987Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c7cd92f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T15:44:32.951189Z",
     "start_time": "2021-06-26T15:44:32.947031Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word\n",
    "                       in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower()\n",
    "                       for word in normalized_text if word and len(word) < 20]\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e138fba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:18.840789Z",
     "start_time": "2021-06-26T14:35:18.837365Z"
    }
   },
   "outputs": [],
   "source": [
    "def ngrammer(tokens, n):\n",
    "    ngrams = []\n",
    "    for i in range(0, len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388a3ad9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:19.337120Z",
     "start_time": "2021-06-26T14:35:19.252848Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = open('data/2ch_corpus.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b057c6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:29.965475Z",
     "start_time": "2021-06-26T14:35:19.712793Z"
    }
   },
   "outputs": [],
   "source": [
    "sents = [['<start>', '<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(texts)][:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81eb2813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:30.634593Z",
     "start_time": "2021-06-26T14:35:30.631941Z"
    }
   },
   "outputs": [],
   "source": [
    "unigrams = Counter()\n",
    "bigrams = Counter()\n",
    "trigrams = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70028ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:31.592407Z",
     "start_time": "2021-06-26T14:35:31.534209Z"
    }
   },
   "outputs": [],
   "source": [
    "for sent in sents:\n",
    "    unigrams.update(sent)\n",
    "    bigrams.update(ngrammer(sent, 2))\n",
    "    trigrams.update(ngrammer(sent, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20159d65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:32.215106Z",
     "start_time": "2021-06-26T14:35:32.198356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<start>', 5000),\n",
       " ('<end>', 2500),\n",
       " ('и', 704),\n",
       " ('не', 687),\n",
       " ('в', 681),\n",
       " ('на', 495),\n",
       " ('что', 388),\n",
       " ('а', 330),\n",
       " ('я', 260),\n",
       " ('с', 258)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb36b7d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:33.021859Z",
     "start_time": "2021-06-26T14:35:33.010067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<start> <start>', 2500),\n",
       " ('<start> а', 100),\n",
       " ('<start> ну', 67),\n",
       " ('<start> я', 66),\n",
       " ('<start> в', 57),\n",
       " ('<start> и', 52),\n",
       " ('<start> ты', 51),\n",
       " ('<start> не', 49),\n",
       " ('<start> это', 42),\n",
       " ('у меня', 40)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fcc7d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:33.712582Z",
     "start_time": "2021-06-26T14:35:33.696690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<start> <start> а', 100),\n",
       " ('<start> <start> ну', 67),\n",
       " ('<start> <start> я', 66),\n",
       " ('<start> <start> в', 57),\n",
       " ('<start> <start> и', 52),\n",
       " ('<start> <start> ты', 51),\n",
       " ('<start> <start> не', 49),\n",
       " ('<start> <start> это', 42),\n",
       " ('<start> <start> но', 38),\n",
       " ('<start> <start> как', 38)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e12ef9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:34.245116Z",
     "start_time": "2021-06-26T14:35:34.238137Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_word_matrix(trigrams):\n",
    "    id2unigram = list(unigrams)\n",
    "    id2bigram = list(bigrams)\n",
    "    unigram2id = {word: i for i, word in enumerate(id2unigram)}\n",
    "    bigram2id = {word: i for i, word in enumerate(id2bigram)}\n",
    "\n",
    "    matrix = np.zeros((len(bigrams),\n",
    "                       len(unigrams)))\n",
    "    for trigram in trigrams:\n",
    "\n",
    "        word1, word2, word3 = trigram.split()\n",
    "        matrix[bigram2id[f'{word1} {word2}']][unigram2id[word3]] = (trigrams[trigram] /\n",
    "                                                                    bigrams[f'{word1} {word2}'])\n",
    "\n",
    "    return matrix, id2unigram, bigram2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190d4a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:34.912045Z",
     "start_time": "2021-06-26T14:35:34.821403Z"
    }
   },
   "outputs": [],
   "source": [
    "trigrams_matrix, id2unigram, bigram2id = get_word_matrix(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb31bb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:35.239574Z",
     "start_time": "2021-06-26T14:35:35.231893Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(matrix, id2unigram, bigram2id, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = bigram2id[start]\n",
    "    current_bigram = start\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
    "        text.append(id2unigram[chosen])\n",
    "        current_bigram = f'{current_bigram.split()[1]} {id2unigram[chosen]}'\n",
    "        if id2unigram[chosen] == '<end>':\n",
    "            chosen = bigram2id[start]\n",
    "            current_bigram = start\n",
    "        current_idx = bigram2id[current_bigram]\n",
    "\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d628c470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:35.709725Z",
     "start_time": "2021-06-26T14:35:35.706827Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_generated():\n",
    "    generated = generate(trigrams_matrix, id2unigram, bigram2id).replace('<end>', '\\n')\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79b74314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:35:41.781762Z",
     "start_time": "2021-06-26T14:35:41.724078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в друзяфках в жжшечке есть один фрактальный медик лол ну нет \n",
      " какашки твои посмотрят на наличии эритроцитов лейкоцитов и пр \n",
      " неправильно считается признаться честно лень искать \n",
      " жс а если оба кружка \n",
      " говновузы готовят софтваре-инженеров хуже чем самообразование по курсам и книгам из интернета \n",
      " пизжу без остановки как пиздлявый ящик вечно кого-то подъебываю подкалываю заебываю \n",
      " совкодаун завидует благородной японии у совков это норма не зря пришёл в этот разговор вставить \n",
      " мне всё пришло мб ты чурка ебаная \n",
      " перекатился \n",
      " ненавижу блядь вебмани \n",
      " лучшая девочка в треде \n",
      " querystring response \n",
      " хирургам лишь\n",
      "\n",
      "и в чём же его уникальность \n",
      " никак я понял что сейчас будет « что » да « как » расспросы эти дурацкие \n",
      " предлагаю скидывать сюда всякие цуиь и шьп касающиеся pr а что же он ебанутый \n",
      " особенно в те моменты когда за 1,5 месяца 7 страниц перерисовки и 2 \n",
      " оформить \n",
      " получите приз \n",
      " лет в 15 благодаря странному стечению обстоятельств начал встречаться с тян \n",
      " по дефолту ходят все \n",
      " тут нет правильного ответа \n",
      " form code monkey like fritos code monkey like tab and mountain dew code monkey append the url to the login\n",
      "\n",
      "выбраться из надоевшей нищеты если на работу возьмут хачкель писать я думаю что добровольно если ты ещё в своём распоряжении средств производства себя а аутсорсу они отваливают только за то чтоб иметь постоянный поток заказов а не врач \n",
      " хирург-кун а если хочется работать а не вованы \n",
      " пойду переслушаю пожалуй \n",
      " а мне казалось что должны то получаться кубические структуры оп если не все компании умеют в удалёнку особенно энтерпрайз \n",
      " 20 сука \n",
      " типа съезд это для кпсс не доросли ещё \n",
      " а вот если тот паттерн на стеклышко маленькими штришками нанести аки решетка дифракционная и лазером туда\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_texts = [get_generated() for _ in range(3)]\n",
    "\n",
    "for text in generated_texts:\n",
    "    print(text, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21712e5a",
   "metadata": {},
   "source": [
    "В тетради с пары я нагенерировала на корпусе двача еще еще три текста с помощью биграмной модели:\n",
    "\n",
    "я вмешиватсья в чем ты как она взорвётся от тебя не в этом году в тяжелой наземной техники программного языка имхо как у нас всё что на картоху с прошлогоднего \n",
    " научная библиотека же негативное \n",
    " то что скажем так просто так же могут \n",
    " ты сегодня начал функционировать за милисекунды \n",
    " наши тыжюризды тупые мрази хватило \n",
    " хули френдзонщицы вконтакте “ warhammer от последней их зеленая обертка вернет функцию \n",
    " а если пизда \n",
    " 04 оператор пси-излучателя 12 \n",
    " хороший итд специализороваынх дорогих кроссах \n",
    " у нас тут надеюсь такая последовательность \n",
    " всех работать над разчудесной странойбуду фазы в\n",
    " \n",
    " тебе экспрессом а не умираим че делаешь \n",
    " ох блять ты ну находи себе учителя могут перед большой член партнерши обычно не надо будет обосрамс \n",
    " нахуй блядь \n",
    " а баб на одном треде задавайте вопросы по теме \n",
    " холодная постель в ближайшем крытом рынке \n",
    " кто-то и запилим когда ты поменьше но как же обратно недавно побрился лебедь душит квазар подталкивает её когда в голове и то можешь сколько символов в голову воину \n",
    " а не опоздайте увидеть тонны знакомых частей гта 5 доларов на сайте или нет \n",
    " да он ебанулся \n",
    " вместо пятого уровня таблицы менделеева –\n",
    " \n",
    " некоторое время и сразу смотрите сколько времени ты ещё в жизни \n",
    " сука мне исполнилось 52 года чтобы не бывает ну знаешь \n",
    " ебать долго думая что некая конкуренция просто на удаленке висит тред начал вторжение в достависте \n",
    " ебать сколько во время когда они не нашёл себя не виновата \n",
    " формула тейлора \n",
    " с сильными \n",
    " ну и гейропейский конкурс \n",
    " ты даже взаимно забегай завтра уебок так она хоть там с солярисами на 9 числа версии 9 часа после покупки авторских прав муслимов трансгендеров и летя быстрее своей квартире были пухи сталин \n",
    " спасибо а потом западная анимация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e95064",
   "metadata": {},
   "source": [
    "Кажется, что качество текстов триграмной модели получилось выше: фразы выглядят чуть более осмысленными и оконченными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7da033",
   "metadata": {},
   "source": [
    "###  Задание 2. (5 баллов) \n",
    "\n",
    "Напишите функцию оценивания нграммов на основе PMI. Используйте эту функцию вместо дефолтной в gensim.models.Phrases. Обучите два последовательных модели Phrases с такой функцией и проанализируйте результаты, получаемые после преобразования текстов двумя Phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "17465f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T23:30:40.210087Z",
     "start_time": "2021-06-26T23:30:40.064802Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "stops = set(stopwords.words('russian') + [\"это\", \"весь\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "376c797d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T23:22:45.081132Z",
     "start_time": "2021-06-26T23:22:45.075712Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    tokens = re.findall('[а-яёa-z0-9]+', text.lower())\n",
    "    normalized_text = [morph.parse(word)[0].normal_form for word \\\n",
    "                                                            in tokens]\n",
    "    normalized_text = [word for word in normalized_text if len(word) > 2 and word not in stops]\n",
    "    \n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8022a94d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T23:22:45.445799Z",
     "start_time": "2021-06-26T23:22:45.441711Z"
    }
   },
   "outputs": [],
   "source": [
    "def scorer(worda_count, wordb_count, bigram_count, len_vocab, min_count, corpus_word_count):\n",
    "    try:\n",
    "        score = ((bigram_count - min_count) / ((worda_count + wordb_count)))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "24f7470d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T23:23:10.119993Z",
     "start_time": "2021-06-26T23:22:46.910378Z"
    }
   },
   "outputs": [],
   "source": [
    "sents = [normalize(text) for text in sent_tokenize(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e10cef46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T23:28:35.646461Z",
     "start_time": "2021-06-26T23:28:35.638927Z"
    }
   },
   "outputs": [],
   "source": [
    "def double_trained_phrases(min_count, threshold):\n",
    "    ph = gensim.models.Phrases(sents, min_count=min_count, \n",
    "                               threshold=threshold, scoring=scorer)\n",
    "    p = gensim.models.phrases.Phraser(ph)\n",
    "    ph2 = gensim.models.Phrases(p[sents], min_count=min_count, \n",
    "                                threshold=threshold, scoring=scorer)\n",
    "    p2 = gensim.models.phrases.Phraser(ph2)\n",
    "    return p, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e51db2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T23:33:33.487409Z",
     "start_time": "2021-06-26T23:33:23.951728Z"
    }
   },
   "outputs": [],
   "source": [
    "p, p2 = double_trained_phrases(1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f3633d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T23:33:39.622961Z",
     "start_time": "2021-06-26T23:33:39.615580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['биос', 'лола']\n",
      "['системный_требование', 'такиеminimum', 'windows_processor_intel_core', 'memory_ram_graphics_nvidia', 'gtx_480_storage_available', 'space', 'сразу', 'минутный', 'faq', 'кадр', 'игра', 'глава', 'разраб', 'который', 'помимо_прочее', 'немного', 'похуесосить_интерстеллара_антинаучность']\n",
      "['вокруг', 'обсуждаться', 'тысяча', 'угодный', 'копрофагия', 'квантовый_физика']\n",
      "['знать', 'москва_питер']\n",
      "['мочь', 'нагуглить']\n",
      "['общий', 'maximum', 'cuteness']\n",
      "['капитализм', 'пирамида', 'тип', 'ммм', 'масштаб', 'государство', 'работать']\n",
      "['выручить', 'продажа', 'акция', 'несколько_тысяча', 'доллар', 'вопреки', 'протест', 'родитель', 'уезжать', 'канада']\n",
      "['ходить_кружка']\n",
      "['генерироваться', 'пустой', 'планета', 'динозавр', 'который', 'убивать', 'посреди', 'планета', 'нибыть', 'камень', 'текст', 'древний', 'цивилизация', 'корабль', 'база', 'торговец', 'нпс', 'который', 'побывать', 'планета', 'втирать', 'первооткрыватель', 'охуенный', 'игра']\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    i = random.randrange(len(sents))\n",
    "    print(p2[p[sents[i]]], end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891e956",
   "metadata": {},
   "source": [
    "Результаты даже после некоторого регулирования параметров min_count и threshold не выглядят впечатляюще, потому что нграм нашлось мало даже несмотря на низкие пороговые значения, хотя те, что нашлись, выглядят адекватно. Возможно, это связано с особенностями корпуса, например, нерегулярной орфографией."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
